{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arghavanMor/HW_mamba/blob/main/zoology_mamba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Notebook, we present our implementation to:\n",
        "\n",
        "**Problem1:** Discover the performance gap between mamba and attention architecture\n",
        "\n",
        "**Problem2:** Close the performance gap\n",
        "########################################################################\n",
        "##**Guideline**\n",
        "* This notebook is a supporting document for implementing the concepts and results in the [presentation report](https://docs.google.com/presentation/d/195nYnjslBa7mfjujT54lI7NlhFGmomwMauxsNm7wvig/edit?usp=sharing). ***This notebook is not completed without the presentation report**.\n",
        "* To be able to execute the code in this notebook, you need to clone the following repository and go to the path `zoology/HW_experiment/` to find relevant implementations:\n",
        "https://github.com/arghavanMor/HW_mamba/\n",
        "\n",
        "* This is a repository sourced from its origin, [Zoology](ttps://github.com/HazyResearch/zoology/). Zoology provides a simple playground for understanding and testing language model architectures on synthetic tasks.\n",
        "\n",
        "* All the implementations related to Problem1&2 can be also find [here](https://github.com/arghavanMor/HW_mamba/tree/main/zoology/HW_experiments) in the repository.\n",
        "* Let's start!\n",
        "\n",
        "############################################################################\n",
        "##**Problem 1**\n",
        "First login to your github account, clone the repository, move to the relevant directory and download and install the dependencies."
      ],
      "metadata": {
        "id": "0BpGm5UD9Uvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#login to git\n",
        "!git config --global user.email \"your email address\""
      ],
      "metadata": {
        "id": "eU9naB5IBvTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#or\n",
        "!git config --global user.name \"username\""
      ],
      "metadata": {
        "id": "QVto7T5ZB02C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clone the repo\n",
        "!git clone https://arghavanMor/HW_mamba.git"
      ],
      "metadata": {
        "id": "eFeObo189UBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zw2Ot7dzS31E"
      },
      "outputs": [],
      "source": [
        "#move to the directory\n",
        "!cd --\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwmB1ONnS8Lc",
        "outputId": "971ee12f-11db-4f21-ff92-0b44e48d2267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/HW_mamba\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (1.26.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (4.66.6)\n",
            "Collecting pydantic<2.5.0,>=2.0.0 (from zoology==0.0.1)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (0.18.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (3.8.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (13.9.4)\n",
            "Collecting ray (from zoology==0.0.1)\n",
            "  Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl (66.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from zoology==0.0.1) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=2.0.0->zoology==0.0.1) (0.7.0)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic<2.5.0,>=2.0.0->zoology==0.0.1)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=2.0.0->zoology==0.0.1) (4.12.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\" in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->zoology==0.0.1) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->zoology==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->zoology==0.0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->zoology==0.0.1) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->zoology==0.0.1) (3.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->zoology==0.0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->zoology==0.0.1) (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray->zoology==0.0.1) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->zoology==0.0.1) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->zoology==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->zoology==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->zoology==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->zoology==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->zoology==0.0.1) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->zoology==0.0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->zoology==0.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->zoology==0.0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->zoology==0.0.1) (2024.8.30)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->zoology==0.0.1) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->zoology==0.0.1) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->zoology==0.0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->zoology==0.0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->zoology==0.0.1) (0.21.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->zoology==0.0.1) (5.0.1)\n",
            "Installing collected packages: pydantic-core, pydantic, ray, zoology\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.23.4\n",
            "    Uninstalling pydantic_core-2.23.4:\n",
            "      Successfully uninstalled pydantic_core-2.23.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Running setup.py develop for zoology\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you'll have pydantic 2.4.2 which is incompatible.\n",
            "langchain 0.3.7 requires pydantic<3.0.0,>=2.7.4, but you'll have pydantic 2.4.2 which is incompatible.\n",
            "langchain-core 0.3.17 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you'll have pydantic 2.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-2.4.2 pydantic-core-2.10.1 ray-2.39.0 zoology-0.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install -e .[extra,analysis] --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_wNCDxVnbt",
        "outputId": "10195d27-8681-4c4f-ac33-d5bc7b80717a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****\n",
        "Now, we can setup our first model using Zoology. To do so, we first need to initialized the model and training config. [Here](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_MHA_basic.py) you can find the setup for a basic attention architecture. I also put the code of configing a model as follows to explain more details.\n",
        "\n",
        "The config starts by setup the train and test data. Class `MQARConfig` in `zoology.data.associative_recall` generate synthetic data for MQAR task, as we already explained the details of the task and the process of synthetic data generation in the presentation.\n",
        "\n",
        "For training dataset, number of examples equals `num_examples=10_000`, vocabulary size is `vocab_size=128` and length of input sequence sets to `input_seq_len=64`.  `num_kv_pairs\": 4` set the number of key-value pairs in the sequnce as explained in the presentation.\n",
        "\n",
        "Similar setup for test data.\n",
        "\n",
        "Then, we config our model. Zoology provides the architecture of different language model in `mixers`. For example [here](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/mixers/attention.py). You can check the implementation of multihead attention transformer using pytorch. Number of heads by default is set to `1`. We need to pass some parameters to config the model, before starting to train the model. Parameters such as vocabulary size `vocab_size = 128`, max position embeding, number of heads and also the threshold for dropout layer."
      ],
      "metadata": {
        "id": "2q7cYWcgCYQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, FunctionConfig, ModuleConfig\n",
        "from zoology.data.associative_recall import MQARConfig\n",
        "\n",
        "\n",
        "config = TrainConfig(\n",
        "    max_epochs=20,\n",
        "    data=DataConfig(\n",
        "        train_configs=[MQARConfig(num_examples=10_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "        test_configs=[MQARConfig(num_examples=1_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        vocab_size=128,\n",
        "        max_position_embeddings=64,\n",
        "        sequence_mixer=ModuleConfig(\n",
        "            name=\"zoology.mixers.attention.MHA\",\n",
        "            kwargs={\"dropout\": 0.1, \"num_heads\": 1}\n",
        "        )\n",
        "    ),\n",
        "\n",
        ")\n",
        "\n",
        "configs = [config]"
      ],
      "metadata": {
        "id": "IY6V0A4hDRoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After setup the config, we can run the following command to train a basic attention-based transformer with `1` head and also find its accuracy and loss on test data in different epochs (`max_epochs = 20` sets in `TrainingConfig`). For example, for this toy model, the best accuracy is around `0.14`."
      ],
      "metadata": {
        "id": "53dyHtTWIz3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vx8GpzXTRX5",
        "outputId": "e6308dd5-926f-4356-ae1f-1336fd1972d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sweep default2024-11-18-02-32-00 with 1 configs\n",
            "No logger specified, skipping...\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m10000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "            \u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.attention.MHA'\u001b[0m,\n",
            "            \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'dropout'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'num_heads'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
            "        \u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mlp.MLP'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'hidden_mult'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'TransformerBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'default'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-18-02-32-00'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'default'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Generating dataset...\n",
            "Generating dataset...\n",
            "Train Epoch 0/20: 100% 313/313 [00:02<00:00, 131.29it/s, loss=3.11]\n",
            "Valid Epoch 0/20: 100% 32/32 [00:00<00:00, 186.59it/s, valid/loss=3.2, valid/accuracy=0.133]\n",
            "Train Epoch 1/20: 100% 313/313 [00:02<00:00, 113.65it/s, loss=2.81]\n",
            "Valid Epoch 1/20: 100% 32/32 [00:00<00:00, 267.09it/s, valid/loss=2.99, valid/accuracy=0.145]\n",
            "Train Epoch 2/20: 100% 313/313 [00:02<00:00, 151.92it/s, loss=2.77]\n",
            "Valid Epoch 2/20: 100% 32/32 [00:00<00:00, 277.32it/s, valid/loss=2.89, valid/accuracy=0.14]\n",
            "Train Epoch 3/20: 100% 313/313 [00:02<00:00, 150.38it/s, loss=2.69]\n",
            "Valid Epoch 3/20: 100% 32/32 [00:00<00:00, 252.77it/s, valid/loss=2.82, valid/accuracy=0.142]\n",
            "Train Epoch 4/20: 100% 313/313 [00:02<00:00, 152.74it/s, loss=2.65]\n",
            "Valid Epoch 4/20: 100% 32/32 [00:00<00:00, 245.36it/s, valid/loss=2.77, valid/accuracy=0.141]\n",
            "Train Epoch 5/20: 100% 313/313 [00:02<00:00, 148.87it/s, loss=2.6]\n",
            "Valid Epoch 5/20: 100% 32/32 [00:00<00:00, 250.17it/s, valid/loss=2.73, valid/accuracy=0.143]\n",
            "Train Epoch 6/20: 100% 313/313 [00:02<00:00, 125.43it/s, loss=2.62]\n",
            "Valid Epoch 6/20: 100% 32/32 [00:00<00:00, 163.63it/s, valid/loss=2.7, valid/accuracy=0.141]\n",
            "Train Epoch 7/20: 100% 313/313 [00:02<00:00, 129.74it/s, loss=2.51]\n",
            "Valid Epoch 7/20: 100% 32/32 [00:00<00:00, 268.42it/s, valid/loss=2.67, valid/accuracy=0.143]\n",
            "Train Epoch 8/20: 100% 313/313 [00:02<00:00, 152.54it/s, loss=2.5]\n",
            "Valid Epoch 8/20: 100% 32/32 [00:00<00:00, 269.95it/s, valid/loss=2.64, valid/accuracy=0.144]\n",
            "Train Epoch 9/20: 100% 313/313 [00:02<00:00, 152.85it/s, loss=2.45]\n",
            "Valid Epoch 9/20: 100% 32/32 [00:00<00:00, 126.30it/s, valid/loss=2.61, valid/accuracy=0.141]\n",
            "Train Epoch 10/20: 100% 313/313 [00:02<00:00, 147.13it/s, loss=2.43]\n",
            "Valid Epoch 10/20: 100% 32/32 [00:00<00:00, 263.04it/s, valid/loss=2.57, valid/accuracy=0.146]\n",
            "Train Epoch 11/20: 100% 313/313 [00:02<00:00, 144.77it/s, loss=2.37]\n",
            "Valid Epoch 11/20: 100% 32/32 [00:00<00:00, 168.14it/s, valid/loss=2.54, valid/accuracy=0.141]\n",
            "Train Epoch 12/20: 100% 313/313 [00:02<00:00, 114.19it/s, loss=2.42]\n",
            "Valid Epoch 12/20: 100% 32/32 [00:00<00:00, 254.02it/s, valid/loss=2.51, valid/accuracy=0.15]\n",
            "Train Epoch 13/20: 100% 313/313 [00:02<00:00, 153.77it/s, loss=2.33]\n",
            "Valid Epoch 13/20: 100% 32/32 [00:00<00:00, 274.66it/s, valid/loss=2.49, valid/accuracy=0.147]\n",
            "Train Epoch 14/20: 100% 313/313 [00:02<00:00, 152.72it/s, loss=2.32]\n",
            "Valid Epoch 14/20: 100% 32/32 [00:00<00:00, 250.11it/s, valid/loss=2.47, valid/accuracy=0.147]\n",
            "Train Epoch 15/20: 100% 313/313 [00:02<00:00, 154.81it/s, loss=2.31]\n",
            "Valid Epoch 15/20: 100% 32/32 [00:00<00:00, 236.66it/s, valid/loss=2.45, valid/accuracy=0.145]\n",
            "Train Epoch 16/20: 100% 313/313 [00:01<00:00, 157.07it/s, loss=2.26]\n",
            "Valid Epoch 16/20: 100% 32/32 [00:00<00:00, 238.59it/s, valid/loss=2.44, valid/accuracy=0.145]\n",
            "Train Epoch 17/20: 100% 313/313 [00:02<00:00, 132.63it/s, loss=2.31]\n",
            "Valid Epoch 17/20: 100% 32/32 [00:00<00:00, 192.24it/s, valid/loss=2.44, valid/accuracy=0.148]\n",
            "Train Epoch 18/20: 100% 313/313 [00:02<00:00, 123.69it/s, loss=2.26]\n",
            "Valid Epoch 18/20: 100% 32/32 [00:00<00:00, 221.55it/s, valid/loss=2.43, valid/accuracy=0.147]\n",
            "Train Epoch 19/20: 100% 313/313 [00:02<00:00, 155.16it/s, loss=2.32]\n",
            "Valid Epoch 19/20: 100% 32/32 [00:00<00:00, 268.58it/s, valid/loss=2.43, valid/accuracy=0.147]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m zoology.launch zoology/HW_experiments/HW_MHA_basic.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, its time to setup our models for problem 1. We should setup one attention-based and one mamba-based architecure. Same as our implementation for attention-based model, Zoology also provide the architecture setup for [mamba](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/mixers/mamba.py).\n",
        "\n",
        "Sine we want to train and test both models on a same set of data, we pack the configuration of both architectures in one and then start the training process. [This source file](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_config.py) contains this configuration.\n",
        "\n",
        "As we highlighted in the presentation report, we define the vocabulary size `1024`, We vary the input length in `[64, 128, 256, 512]` and the number of key-value pairs in `[4, 8, 16, 32, 64, 128]` to explore different level of complexity for MQAR task. For the test data, we also generate testset with input length and number of key-value pairs not seen during the training. As requested in the problem, with each setup, we generate `20,000` train data and `1000` test data.\n",
        "\n",
        "The batch size is `128`, the model size changes in `[64, 128, 256]`. The learning rate is in `np.logspace(-3, -1.5, 4)` and number of epoch sets to `20`.\n",
        "\n",
        "\n",
        "After setup the config of both models and before start the training process, we login into W&B to log all the experiment results for furthur investigation. After login into the `wandba`, we should update the `project_name` and `enitiy` to our relevant project and entity in wandb, in the `TrainConfig` in the [configuration](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_config.py) setup.\n",
        "\n",
        "\n",
        "To speed up the process and avoid any crash or intruption, we can train and evaluate each model seperately by removing the name of the other model from list of the models in the [configuration](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_config.py) setup. To be able to train mamba architecture, we need to install differant packages such as `causal-conv1d` and resolve some dependencies. You can find them in **Draft** section in this notebook."
      ],
      "metadata": {
        "id": "BHMig57gKAsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "8vw-QA2YOeMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "V8oJZVAWOlY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training both mamaba and attention-based models, we want to compare their performance on MQAR tasks with different complexities (input length or number of key-value pairs) and discover if there is any gap between the performance of our two toy models on MQAR task.\n",
        "\n",
        "\n",
        "In the pervious section, we vary the input length in `[64, 128, 256, 512]` and number of key-value pairs in `[4, 8, 16, 32, 64, 128]`. During the validation process, in [train.py](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/train.py), there is a possibility to groupy the `accuracy` on the sythetic test data either by input length, `input_seq_len` or number of key-value pairs `num_kv_pairs`. Then, the result will contain different accuracy on the test set such ash `accuracy/input_seq_len_64` or `accuracy/num_kv_pairs_4` and so on. We can change this setup by varaible `slice_keys` in [trainConfig](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_config.py) in our configuration by setup its value either to `input_seq_len` or `num_kv_pairs`"
      ],
      "metadata": {
        "id": "K_7hJ90lTLHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# execute two times. first slice_keys=['num_kv_pairs'], second time slice_keys=['input_seq_len']\n",
        "!python -m zoology.launch zoology/HW_experiments/HW_config.py"
      ],
      "metadata": {
        "id": "iosHw7CoPVSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now its time to plot our results. In the wandb logs for executing each model, we need to find its `lunch_id` and use it here to be able to collect the results of our models on test data. Before running the following code to plot the result, we need to update the `project_name` and `entity name` of our wandb setupin the following code. As we can see in the results, the performance of mamba model decrease significanty by increasing the number key-value pairs in the sequence of input (increasing the complexity of MQAR task). We discuss more details in the presentation report."
      ],
      "metadata": {
        "id": "VxigQn40P9bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from zoology.analysis.utils import fetch_wandb_runs\n",
        "import pdb\n",
        "\n",
        "\n",
        "def plot(\n",
        "    df: pd.DataFrame,\n",
        "    max_seq_len: int = 512,\n",
        "):\n",
        "    seq_len_key = \"data.train_configs.2.input_seq_len\"\n",
        "\n",
        "\n",
        "    accuracy_keys = [\"valid/num_kv_pairs/accuracy-4\", \"valid/num_kv_pairs/accuracy-8\", \"valid/num_kv_pairs/accuracy-16\",\n",
        "                    \"valid/num_kv_pairs/accuracy-32\", \"valid/num_kv_pairs/accuracy-64\", \"valid/num_kv_pairs/accuracy-128\"]\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))  # 2 rows, 3 columns\n",
        "\n",
        "    # Iterate through keys and axes\n",
        "    for ax, accuracy_key in zip(axes.flat, accuracy_keys):\n",
        "        # Prepare data for the specific accuracy_key\n",
        "        plot_df = df.groupby([\n",
        "            \"model.name\",\n",
        "            \"model.d_model\",\n",
        "            seq_len_key\n",
        "        ])[accuracy_key].max().reset_index()\n",
        "\n",
        "        sns.lineplot(\n",
        "            data=plot_df[plot_df[seq_len_key] <= max_seq_len],\n",
        "            x=\"model.d_model\",\n",
        "            y=accuracy_key,\n",
        "            hue=\"model.name\",\n",
        "            marker=\"o\",\n",
        "            ax=ax\n",
        "        )\n",
        "\n",
        "        match = re.search(r\"valid/([^/]+)/accuracy-(\\d+)\", accuracy_key)\n",
        "        if match:\n",
        "          number = match.group(2)  # Captures \"4\"\n",
        "        ax.set_title(f\"num_kv_pairs_{number}\")\n",
        "        ax.set_xlabel(\"Model dimension\")\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "        ax.set_xticks([64, 128, 256])\n",
        "        ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "  df = fetch_wandb_runs(\n",
        "      launch_id=[\n",
        "          \"default-2024-11-16-05-24-11\",\n",
        "          \"default-2024-11-16-20-50-22\"\n",
        "      ],\n",
        "      project_name=\"HW_mamba\"\n",
        "  )\n",
        "\n",
        "  plot(df=df)\n",
        "  plt.savefig(\"/content/HW_mamba/results_kv.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "IfDPUyTwJ5-J",
        "outputId": "f82615c2-77ad-45e6-a495-5e08749f246d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we plot our results based on the `input sequence length`. As we can see in the second plot, when the sequnce is not very large (i.e 64 or 128), the performance of mamba model at the low model dimension is significantly lower than attention but when the model dimension increases, the performance of mamba can match the attention-based model. However, we the input length increases (up to 512), even in high dimension model, there is a significant gap between the performance of mamba and attention architecture."
      ],
      "metadata": {
        "id": "vMU7pckPVNQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from zoology.analysis.utils import fetch_wandb_runs\n",
        "import pdb\n",
        "\n",
        "\n",
        "def plot(\n",
        "    df: pd.DataFrame,\n",
        "    max_seq_len: int = 512,\n",
        "):\n",
        "    seq_len_key = \"data.train_configs.2.input_seq_len\"\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_keys = [\"valid/input_seq_len/accuracy-64\", \"valid/input_seq_len/accuracy-128\", \"valid/input_seq_len/accuracy-256\",\n",
        "                    \"valid/input_seq_len/accuracy-512\"]\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 10))  # 2 rows, 3 columns\n",
        "\n",
        "    # Iterate through keys and axes\n",
        "    for ax, accuracy_key in zip(axes.flat, accuracy_keys):\n",
        "        # Prepare data for the specific accuracy_key\n",
        "        plot_df = df.groupby([\n",
        "            \"model.name\",\n",
        "            \"model.d_model\",\n",
        "            seq_len_key\n",
        "        ])[accuracy_key].max().reset_index()\n",
        "\n",
        "        sns.lineplot(\n",
        "            data=plot_df[plot_df[seq_len_key] <= max_seq_len],\n",
        "            x=\"model.d_model\",\n",
        "            y=accuracy_key,\n",
        "            hue=\"model.name\",\n",
        "            marker=\"o\",\n",
        "            ax=ax\n",
        "        )\n",
        "\n",
        "        match = re.search(r\"valid/([^/]+)/accuracy-(\\d+)\", accuracy_key)\n",
        "        if match:\n",
        "          number = match.group(2)  # Captures \"4\"\n",
        "        ax.set_title(f\"input_seq_length_{number}\")\n",
        "        ax.set_xlabel(\"Model dimension\")\n",
        "        ax.set_ylabel(\"Accuracy\")\n",
        "        ax.set_xticks([64, 128, 256])\n",
        "        ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "  df = fetch_wandb_runs(\n",
        "      launch_id=[\n",
        "\n",
        "          \"default-2024-11-17-04-29-05\",\n",
        "          \"default-2024-11-16-22-09-21\"\n",
        "      ],\n",
        "      project_name=\"HW_mamba\"\n",
        "  )\n",
        "\n",
        "  plot(df=df)\n",
        "  plt.savefig(\"/content/HW_mamba/results_length.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "ncs3NNksVMVL",
        "outputId": "b82238cd-edc6-4d88-c1cd-e66b025c712a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****\n",
        "###############################################################################\n",
        "##**Problem2**\n",
        "The goal of second problem is to close the gap between Linear architecures like mamba and attention-based models.\n",
        "\n",
        "In the presentation report, we explained some details about  `attention-to-mamba initialization` technique. Basically, to implement this technique, we need to first initialize (replace) the parameters of mamba (X, B, C) with attention parameters (K, Q, V).\n",
        "\n",
        "\n",
        "To do so, we need a pre-trained mamba and transformer model. For this case, we can refer to our models that we trained for `problem1`. However, for simplification (learning rate rate, different model size, input_length, etc), I created a seperate [config file](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/HW_experiments/HW_mamba_basic.py) to train a mamba architecture. At the begining of this notebook, we also trained a basic attention based model that we use here.\n",
        "\n",
        "\n",
        "This time, we need to save our torch model to be able to load it for furthur investigation. To do so, I added the following function into [`train.py`](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/train.py) in the `Trainer` class and call the `save_model` method at the last step of `fit` function in the same class. Due to time limitation, I change the path in the `save_model` method manually to save both `attention` and `mamba` models. However, in future we can pass it as an argument to the `Trainer` class.\n",
        "\n",
        "```python\n",
        "def save_model(self, save_dir: str):\n",
        "        \"\"\"\n",
        "           Save the model and tokenizer to the specified directory.\n",
        "        \"\"\"\n",
        "        torch.save(self.model.state_dict(), save_dir)\n",
        "```\n",
        "\n",
        "and then call it after fiting the model:\n",
        "\n",
        "```python\n",
        " self.save_model(\"/content/HW_mamba/attn_model\")\n",
        " ```\n",
        "\n",
        "\n",
        " Now, to start solving problem 2, we can load both models as follow. To be able to creat an instance of the model, we need pass it the model config. To do so, for each model I first, set their config and then load the pre-trained model. By calling `LanguageModel` in Zoology, we can create an instance with any config that it supports."
      ],
      "metadata": {
        "id": "HSCsLfkYWVVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m zoology.launch zoology/HW_experiments/HW_mamba_basic.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Gfa52c4oOyW",
        "outputId": "0c5608b9-520d-455b-a5b0-2c0505409918"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sweep default2024-11-18-04-56-28 with 1 configs\n",
            "No logger specified, skipping...\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m10000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mlp.MLP'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'hidden_mult'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'default'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-18-04-56-28'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'default'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Generating dataset...\n",
            "Generating dataset...\n",
            "Train Epoch 0/20: 100% 313/313 [00:05<00:00, 61.21it/s, loss=4.17] \n",
            "Valid Epoch 0/20: 100% 32/32 [00:00<00:00, 183.77it/s, valid/loss=4.18, valid/accuracy=0.0173]\n",
            "Train Epoch 1/20: 100% 313/313 [00:02<00:00, 155.63it/s, loss=4.16]\n",
            "Valid Epoch 1/20: 100% 32/32 [00:00<00:00, 281.74it/s, valid/loss=4.17, valid/accuracy=0.0171]\n",
            "Train Epoch 2/20: 100% 313/313 [00:02<00:00, 152.83it/s, loss=4.16]\n",
            "Valid Epoch 2/20: 100% 32/32 [00:00<00:00, 301.45it/s, valid/loss=4.17, valid/accuracy=0.0166]\n",
            "Train Epoch 3/20: 100% 313/313 [00:02<00:00, 151.07it/s, loss=4.16]\n",
            "Valid Epoch 3/20: 100% 32/32 [00:00<00:00, 296.98it/s, valid/loss=4.17, valid/accuracy=0.0161]\n",
            "Train Epoch 4/20: 100% 313/313 [00:02<00:00, 152.57it/s, loss=4.15]\n",
            "Valid Epoch 4/20: 100% 32/32 [00:00<00:00, 299.92it/s, valid/loss=4.17, valid/accuracy=0.0154]\n",
            "Train Epoch 5/20: 100% 313/313 [00:02<00:00, 138.23it/s, loss=4.15]\n",
            "Valid Epoch 5/20: 100% 32/32 [00:00<00:00, 233.58it/s, valid/loss=4.17, valid/accuracy=0.0163]\n",
            "Train Epoch 6/20: 100% 313/313 [00:02<00:00, 112.87it/s, loss=4.14]\n",
            "Valid Epoch 6/20: 100% 32/32 [00:00<00:00, 306.36it/s, valid/loss=4.17, valid/accuracy=0.0179]\n",
            "Train Epoch 7/20: 100% 313/313 [00:02<00:00, 150.48it/s, loss=4.14]\n",
            "Valid Epoch 7/20: 100% 32/32 [00:00<00:00, 309.72it/s, valid/loss=4.17, valid/accuracy=0.0182]\n",
            "Train Epoch 8/20: 100% 313/313 [00:02<00:00, 151.97it/s, loss=4.11]\n",
            "Valid Epoch 8/20: 100% 32/32 [00:00<00:00, 303.37it/s, valid/loss=4.19, valid/accuracy=0.0186]\n",
            "Train Epoch 9/20: 100% 313/313 [00:02<00:00, 150.32it/s, loss=4.05]\n",
            "Valid Epoch 9/20: 100% 32/32 [00:00<00:00, 282.86it/s, valid/loss=4.21, valid/accuracy=0.0185]\n",
            "Train Epoch 10/20: 100% 313/313 [00:02<00:00, 153.75it/s, loss=3.94]\n",
            "Valid Epoch 10/20: 100% 32/32 [00:00<00:00, 290.83it/s, valid/loss=4.23, valid/accuracy=0.0174]\n",
            "Train Epoch 11/20: 100% 313/313 [00:02<00:00, 131.30it/s, loss=3.77]\n",
            "Valid Epoch 11/20: 100% 32/32 [00:00<00:00, 231.68it/s, valid/loss=4.27, valid/accuracy=0.018]\n",
            "Train Epoch 12/20: 100% 313/313 [00:02<00:00, 118.31it/s, loss=3.59]\n",
            "Valid Epoch 12/20: 100% 32/32 [00:00<00:00, 310.36it/s, valid/loss=4.32, valid/accuracy=0.018]\n",
            "Train Epoch 13/20: 100% 313/313 [00:02<00:00, 154.46it/s, loss=3.4]\n",
            "Valid Epoch 13/20: 100% 32/32 [00:00<00:00, 284.69it/s, valid/loss=4.37, valid/accuracy=0.0182]\n",
            "Train Epoch 14/20: 100% 313/313 [00:02<00:00, 151.29it/s, loss=3.24]\n",
            "Valid Epoch 14/20: 100% 32/32 [00:00<00:00, 280.59it/s, valid/loss=4.42, valid/accuracy=0.0176]\n",
            "Train Epoch 15/20: 100% 313/313 [00:02<00:00, 148.08it/s, loss=3.12]\n",
            "Valid Epoch 15/20: 100% 32/32 [00:00<00:00, 295.30it/s, valid/loss=4.45, valid/accuracy=0.0173]\n",
            "Train Epoch 16/20: 100% 313/313 [00:02<00:00, 149.28it/s, loss=3.06]\n",
            "Valid Epoch 16/20: 100% 32/32 [00:00<00:00, 291.58it/s, valid/loss=4.47, valid/accuracy=0.0166]\n",
            "Train Epoch 17/20: 100% 313/313 [00:02<00:00, 121.70it/s, loss=3.05]\n",
            "Valid Epoch 17/20: 100% 32/32 [00:00<00:00, 197.29it/s, valid/loss=4.47, valid/accuracy=0.0187]\n",
            "Train Epoch 18/20: 100% 313/313 [00:02<00:00, 128.08it/s, loss=3.06]\n",
            "Valid Epoch 18/20: 100% 32/32 [00:00<00:00, 232.19it/s, valid/loss=4.47, valid/accuracy=0.0171]\n",
            "Train Epoch 19/20: 100% 313/313 [00:02<00:00, 152.59it/s, loss=3.07]\n",
            "Valid Epoch 19/20: 100% 32/32 [00:00<00:00, 275.85it/s, valid/loss=4.46, valid/accuracy=0.0174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zoology.model import LanguageModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "0g0FZepqgDG8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model config same as the config used during the training process.\n",
        "#We don't need to pass the data for training and test for this config here, but I need more time to figure out how to only pass the model config not the whole data and model setup\n",
        "\n",
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, FunctionConfig, ModuleConfig\n",
        "from zoology.data.associative_recall import MQARConfig\n",
        "\n",
        "\n",
        "att_config = TrainConfig(\n",
        "    max_epochs=20,\n",
        "    data=DataConfig(\n",
        "        train_configs=[MQARConfig(num_examples=10_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "        test_configs=[MQARConfig(num_examples=1_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        vocab_size=128,\n",
        "        max_position_embeddings=64,\n",
        "        sequence_mixer=ModuleConfig(\n",
        "            name=\"zoology.mixers.attention.MHA\",\n",
        "            kwargs={\"dropout\": 0.1, \"num_heads\": 1}\n",
        "        )\n",
        "    ),\n",
        "\n",
        ")\n",
        "\n",
        "configs = [config]"
      ],
      "metadata": {
        "id": "nhqp2WNEgR9z"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating an instance of an attention-based model\n",
        "att_model = LanguageModel(config=att_config.model)"
      ],
      "metadata": {
        "id": "u6tgQnK8gTea"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "att_model.load_state_dict(torch.load(\"/content/HW_mamba/attn_model\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhNbtOd4gbxi",
        "outputId": "7446969f-362c-40c4-c88e-17ef17a264fd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the `eval` result, our model has two layers, with an attention layer, `MHA` and and MLP layer, `MLP`. For each layer, we need to collect its attention parameters from `Wqkv` and use it to inialize the parameter of mamba."
      ],
      "metadata": {
        "id": "8hPA-OaDcuCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shows the model architecture\n",
        "att_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7w5vpv-bPyZ",
        "outputId": "f658b8c5-d1f1-4f91-87c8-f0a05a4ae6c5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (backbone): LMBackbone(\n",
              "    (embeddings): TokenEmbeddings(\n",
              "      (word_embeddings): Embedding(128, 128)\n",
              "      (position_embeddings): Embedding(64, 128)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerBlock(\n",
              "        (sequence_mixer): MHA(\n",
              "          (Wqkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (inner_attn): SelfAttention()\n",
              "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (state_mixer): MLP(\n",
              "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): TransformerBlock(\n",
              "        (sequence_mixer): MHA(\n",
              "          (Wqkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (inner_attn): SelfAttention()\n",
              "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (state_mixer): MLP(\n",
              "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        )\n",
              "        (dropout1): Dropout(p=0.0, inplace=False)\n",
              "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout2): Dropout(p=0.0, inplace=False)\n",
              "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (drop_f): Dropout(p=0.0, inplace=False)\n",
              "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=128, out_features=128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for example with this code we can have access to the MLP layer of the model\n",
        "# To apply the knowledge distillization step, we need to freez MLP layer\n",
        "mlp_layer = att_model.backbone.layers[0].state_mixer\n",
        "print(mlp_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGmW0gDI32nL",
        "outputId": "cb17b99f-6e1d-42f9-966e-cdb090108a30"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Collecting the three attention vectors from our pretrained model\n",
        "#we need them for initialzing the parameters of mamba model\n",
        "\n",
        "source_wqkv = att_model.backbone.layers[0].sequence_mixer.Wqkv\n",
        "Q= source_wqkv.weight[:128, :]\n",
        "K= source_wqkv.weight[128:256, :]\n",
        "V= source_wqkv.weight[256:, :]"
      ],
      "metadata": {
        "id": "8rzZBaDWeF1O"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We repeat the same process to load our mamba model for furthur investigation."
      ],
      "metadata": {
        "id": "qUZIrA55gky9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, FunctionConfig, ModuleConfig\n",
        "from zoology.data.associative_recall import MQARConfig\n",
        "\n",
        "\n",
        "config_mamba = TrainConfig(\n",
        "    max_epochs=20,\n",
        "    data=DataConfig(\n",
        "        train_configs=[MQARConfig(num_examples=10_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "        test_configs=[MQARConfig(num_examples=1_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "    ),\n",
        "\n",
        "    model = ModelConfig(\n",
        "        block_type=\"MambaBlock\",\n",
        "        vocab_size=128,\n",
        "        max_position_embeddings=0,\n",
        "        n_layers=2,\n",
        "        sequence_mixer=dict(\n",
        "            name=\"zoology.mixers.mamba.Mamba\",\n",
        "            kwargs={\"d_state\": 16}),\n",
        "        ),\n",
        "        name=\"mamba\",\n",
        "\n",
        ")\n",
        "\n",
        "configs = [config]"
      ],
      "metadata": {
        "id": "9w-bS_-KmlBi"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mamba = LanguageModel(config=config_mamba.model)"
      ],
      "metadata": {
        "id": "wFSqJmpnmqgY"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mamba.load_state_dict(torch.load(\"/content/HW_mamba/mamba_model\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI8_0XPS3nn0",
        "outputId": "ccc53048-3ccd-42f3-a3d3-b5cc47e621b5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pre-trained mamba model also has two layers, both with same setup. In this pretrained model, we need to initialize its paramemters (in_proj, x_proj, dt_proj) with K, Q and V."
      ],
      "metadata": {
        "id": "zC4hkZ7vg7AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mamba.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4knPqvua3vAf",
        "outputId": "1e7e611c-2cfd-4ca8-edf5-d01befe2ef5c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (backbone): LMBackbone(\n",
              "    (embeddings): TokenEmbeddings(\n",
              "      (word_embeddings): Embedding(128, 128)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x MambaBlock(\n",
              "        (mixer): Mamba(\n",
              "          (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
              "          (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
              "          (act): SiLU()\n",
              "          (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
              "          (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
              "          (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "        )\n",
              "        (norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (drop_f): Dropout(p=0.0, inplace=False)\n",
              "    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=128, out_features=128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test= model_mamba.backbone.layers[0].mixer\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdLXobsc5wVu",
        "outputId": "af23fe40-2d0b-459a-f659-2ebc636ba342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mamba(\n",
            "  (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
            "  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
            "  (act): SiLU()\n",
            "  (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
            "  (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
            "  (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I need to investigate more, but probebly weight of in_proj can be refer as A, wight of conv1d as B and wight of out_proj as C\n",
        "A= model_mamba.backbone.layers[0].mixer.in_proj.weight\n",
        "B =model_mamba.backbone.layers[0].mixer.conv1d.weight\n",
        "C= model_mamba.backbone.layers[0].mixer.out_proj.weight\n",
        "print(C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmOJ5oVGj-40",
        "outputId": "889e288f-78c3-4eb9-c02b-268e956eb28e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0190,  0.0321, -0.0158,  ..., -0.0064,  0.0047,  0.0190],\n",
            "        [-0.0154,  0.0285, -0.0233,  ...,  0.0253,  0.0278,  0.0092],\n",
            "        [-0.0107,  0.0628, -0.0505,  ..., -0.0104, -0.0191,  0.0840],\n",
            "        ...,\n",
            "        [-0.0035, -0.0416, -0.0038,  ...,  0.0193, -0.0202,  0.0492],\n",
            "        [-0.0256, -0.0148, -0.0202,  ..., -0.0028, -0.0057,  0.0272],\n",
            "        [ 0.0168, -0.0055,  0.0071,  ...,  0.0104, -0.0221,  0.0432]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete answering `problem 2`, we may also need to update the implementation of mamba architecutre [here](https://github.com/arghavanMor/HW_mamba/blob/main/zoology/mixers/mamba.py) where we are initializing the parameters.\n",
        "\n",
        "\n",
        "After updating the the parameters, we should apply one of the distilling steps to finetune the new model (attention initiliazed mamba) with etheir `KL-divergence` or `SeqKD`. More details are in the presentation report.\n",
        "****\n"
      ],
      "metadata": {
        "id": "Xxzo9Kd5jAIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Draft section (not part of the solutions to the problems)***\n",
        "\n",
        "This section is a draft on different installation and dependency conflict or run time bug resolving that may help in replicating this notebook. In case of a bug or error, maybe can search in this draft section to find a solution to solve it."
      ],
      "metadata": {
        "id": "6oNnAnt-mZon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2ta_na2wxkN",
        "outputId": "18ebc0b4-8bc8-4650-da92-6d52dbf10251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF5ZxN3vw0je",
        "outputId": "988802f9-379e-4a0f-e87a-81bebeaae180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYdFVakI4Scg",
        "outputId": "9e69adb6-5ea6-4e42-ea9f-1a41a449e824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paFzO_2qaX32",
        "outputId": "d8fb292f-ab64-4404-bdf2-ce54d78c058e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To push changes to github"
      ],
      "metadata": {
        "id": "bJjA30GmnqsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "12gP0tUlnfgp"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"using hybrid model to mix wity attention based model with convBase\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfUgz5v1ngVf",
        "outputId": "fa6305e5-72ea-4be4-f121-0516ea83c81f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main f96c15d] using hybrid model to mix wity attention based model with convBase\n",
            " 1 file changed, 2 insertions(+)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD_pQpBDnnRU",
        "outputId": "19bf429b-ebd4-417c-c5da-4c637bbfe6b8"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 9, done.\n",
            "Counting objects:  11% (1/9)\rCounting objects:  22% (2/9)\rCounting objects:  33% (3/9)\rCounting objects:  44% (4/9)\rCounting objects:  55% (5/9)\rCounting objects:  66% (6/9)\rCounting objects:  77% (7/9)\rCounting objects:  88% (8/9)\rCounting objects: 100% (9/9)\rCounting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  20% (1/5)\rCompressing objects:  40% (2/5)\rCompressing objects:  60% (3/5)\rCompressing objects:  80% (4/5)\rCompressing objects: 100% (5/5)\rCompressing objects: 100% (5/5), done.\n",
            "Writing objects:  20% (1/5)\rWriting objects:  40% (2/5)\rWriting objects:  60% (3/5)\rWriting objects:  80% (4/5)\rWriting objects: 100% (5/5)\rWriting objects: 100% (5/5), 562 bytes | 562.00 KiB/s, done.\n",
            "Total 5 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/arghavanMor/HW_mamba.git\n",
            "   9efddc3..f96c15d  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMwK32HsaAqT",
        "outputId": "245c4060-aa5b-4979-bdc4-d4668c9a34de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'causal-conv1d'...\n",
            "remote: Enumerating objects: 343, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 343 (delta 107), reused 82 (delta 82), pack-reused 218 (from 1)\u001b[K\n",
            "Receiving objects: 100% (343/343), 81.62 KiB | 189.00 KiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Dao-AILab/causal-conv1d.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmdJ01tpaDXr",
        "outputId": "eded6143-e0e7-4026-c617-41c0b911115f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HW_mamba/causal-conv1d\n"
          ]
        }
      ],
      "source": [
        "cd causal-conv1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiSN6gTBafBb"
      },
      "outputs": [],
      "source": [
        "rm -rf *.egg.info build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc9sD2Mbakng",
        "outputId": "4ae9aa36-1d68-4d42-93f0-2af8e1ae41b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'v1.4.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at f8c2467 Bump to v1.4.0\n"
          ]
        }
      ],
      "source": [
        "!git checkout v1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxqyPopifAoe"
      },
      "outputs": [],
      "source": [
        "!export CAUSAL_CONV1D_FORCE_BUILD=TRUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mwJ3DMa6PU",
        "outputId": "acf80be0-2883-4699-b1ba-091bbe0ce72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/HW_mamba/causal-conv1d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.4.0) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.4.0) (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.4.0) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (2024.10.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.4.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal_conv1d==1.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal_conv1d==1.4.0) (1.3.0)\n",
            "Building wheels for collected packages: causal_conv1d\n",
            "  Building wheel for causal_conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for causal_conv1d: filename=causal_conv1d-1.4.0-cp310-cp310-linux_x86_64.whl size=103612780 sha256=b37d1d2fcbb3d79446fb7f08690a6136da3c92be0ca2aab1629a1ab3d451ce9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/b8/75/afa073c714a371e7f79e6e0875bb3215025df315ae036574d5\n",
            "Successfully built causal_conv1d\n",
            "Installing collected packages: causal_conv1d\n",
            "  Attempting uninstall: causal_conv1d\n",
            "    Found existing installation: causal-conv1d 1.1.1\n",
            "    Uninstalling causal-conv1d-1.1.1:\n",
            "      Successfully uninstalled causal-conv1d-1.1.1\n",
            "Successfully installed causal_conv1d-1.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSvrEiQ-2Ix9",
        "outputId": "1c8f44c1-6269-46dd-eb4b-faea1c5a1c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.2)\n"
          ]
        }
      ],
      "source": [
        "pip install setuptools wheel packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXMotlwSXkPi",
        "outputId": "f77e5317-c191-4158-9a29-eea7fba4d1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mamba_ssm in /usr/local/lib/python3.10/dist-packages (1.2.0.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mamba_ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yidyv06kYS-8",
        "outputId": "d728f57a-45f2-4911-9b42-a40864df0354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LctwZFBRXGkO",
        "outputId": "4dcc9e77-b61d-4b7b-bd14-47984df4d069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mamba'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (300/300), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 648 (delta 228), reused 206 (delta 196), pack-reused 348 (from 1)\u001b[K\n",
            "Receiving objects: 100% (648/648), 1.55 MiB | 4.05 MiB/s, done.\n",
            "Resolving deltas: 100% (340/340), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/state-spaces/mamba.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOPWHVURkq_9",
        "outputId": "a05ada10-b719-4137-a9ff-18a23f1e5ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mamba\n"
          ]
        }
      ],
      "source": [
        "cd mamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XirRSoQFkuPU"
      },
      "outputs": [],
      "source": [
        "rm -rf *.egg.info build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HiMUtEdlQBY",
        "outputId": "68f2ede2-cd13-44ac-b607-70dfbe41b2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'v2.2.2'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 8ffd905 Fix varlen generation by passing seq_idx to causal_conv1d\n"
          ]
        }
      ],
      "source": [
        "!git checkout v2.2.2 # current latest version tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJn4DdFfldSV"
      },
      "outputs": [],
      "source": [
        "!export MAMBA_FORCE_BUILD=TRUE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBgQf6wKJquV",
        "outputId": "f8db974a-245d-432d-a330-6023599ad2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/zoology\n"
          ]
        }
      ],
      "source": [
        "cd --"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIE0aNY8lmBu",
        "outputId": "fee80724-6ffd-4e44-adcf-4a72dccccd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/mamba\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm==2.2.2) (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm==2.2.2) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm==2.2.2) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm==2.2.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: mamba_ssm\n",
            "  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba_ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=343412612 sha256=150be68a91b3444b35ee2cda6a4790aaf83711009a8bf8e91afc7a316b091df6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7nzcq2ay/wheels/fb/bd/db/47d39b5aa5f1c5ccf671710c66e7a084dd82fb317f85f52625\n",
            "Successfully built mamba_ssm\n",
            "Installing collected packages: mamba_ssm\n",
            "  Attempting uninstall: mamba_ssm\n",
            "    Found existing installation: mamba-ssm 1.2.0.post1\n",
            "    Uninstalling mamba-ssm-1.2.0.post1:\n",
            "      Successfully uninstalled mamba-ssm-1.2.0.post1\n",
            "Successfully installed mamba_ssm-2.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvuoRC1O4Vl3",
        "outputId": "e716653d-4a29-4bfd-a29d-dc6d6ec6cbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE\n",
            "  Downloading https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.4.0/causal_conv1d-1.4.0+cu118torch2.0cxx11abiFALSE-cp310-cp310-linux_x86_64.whl (103.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.6/103.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (24.2)\n",
            "Collecting ninja (from causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (2024.10.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal-conv1d==1.4.0+cu118torch2.0cxx11abiFALSE) (1.3.0)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja, causal-conv1d\n",
            "Successfully installed causal-conv1d-1.4.0 ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.4.0/causal_conv1d-1.4.0+cu118torch2.0cxx11abiFALSE-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMWlPMMQ5Ih4",
        "outputId": "3ce96193-7da4-4688-cb32-24dbf32fceeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m590.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1) (2024.10.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.1) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed torch-2.1.1+cu118 torchaudio-2.1.1+cu118 torchvision-0.16.1+cu118 triton-2.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2fJM2GEl53Ck",
        "outputId": "4057965b-41ab-4594-8c65-7953630a741f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting causal_conv1d==1.1.1\n",
            "  Downloading causal_conv1d-1.1.1.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.1.1) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.1.1) (24.2)\n",
            "Collecting buildtools (from causal_conv1d==1.1.1)\n",
            "  Downloading buildtools-1.0.6.tar.gz (446 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.5/446.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from causal_conv1d==1.1.1) (1.11.1.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.0.36)\n",
            "Collecting argparse (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting twisted (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading twisted-24.10.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting simplejson (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting furl (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.32.3)\n",
            "Collecting docopt (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from buildtools->causal_conv1d==1.1.1) (3.1.4)\n",
            "Collecting redo (from buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading redo-3.0.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (2024.10.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d==1.1.1) (2.1.0)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from furl->buildtools->causal_conv1d==1.1.1) (1.16.0)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->buildtools->causal_conv1d==1.1.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->buildtools->causal_conv1d==1.1.1) (3.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->causal_conv1d==1.1.1) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from twisted->buildtools->causal_conv1d==1.1.1) (24.2.0)\n",
            "Collecting automat>=24.8.0 (from twisted->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from twisted->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from twisted->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from twisted->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting zope-interface>=5 (from twisted->buildtools->causal_conv1d==1.1.1)\n",
            "  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=61.0 in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->twisted->buildtools->causal_conv1d==1.1.1) (75.1.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->twisted->buildtools->causal_conv1d==1.1.1) (2.1.0)\n",
            "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Downloading redo-3.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading twisted-24.10.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: causal_conv1d, buildtools, docopt\n",
            "  Building wheel for causal_conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for causal_conv1d: filename=causal_conv1d-1.1.1-cp310-cp310-linux_x86_64.whl size=13531321 sha256=f572458de281ed15fbd6f9262d44d66591416c7a903c4da699ed4d70b3cf5a83\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9e/69/9060a1871f461dfca87b667350f5728d44c555f98dacaf04ff\n",
            "  Building wheel for buildtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for buildtools: filename=buildtools-1.0.6-py3-none-any.whl size=512341 sha256=984009974d1927ec1822621921268c919d0b0344c4d62a1db02a2d51968b813f\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/e9/2a/625d99dffa430d0b4293d3d386f63e0eb8edeeb54f3f29d208\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=1065a041a1e212068f6f9cb5dd88db5b739653c9e62def43c45b4b06f9bf44b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built causal_conv1d buildtools docopt\n",
            "Installing collected packages: redo, docopt, argparse, zope-interface, simplejson, orderedmultidict, incremental, hyperlink, constantly, automat, twisted, furl, buildtools, causal_conv1d\n",
            "  Attempting uninstall: causal_conv1d\n",
            "    Found existing installation: causal-conv1d 1.4.0\n",
            "    Uninstalling causal-conv1d-1.4.0:\n",
            "      Successfully uninstalled causal-conv1d-1.4.0\n",
            "Successfully installed argparse-1.4.0 automat-24.8.1 buildtools-1.0.6 causal_conv1d-1.1.1 constantly-23.10.4 docopt-0.6.2 furl-2.1.3 hyperlink-21.0.0 incremental-24.7.2 orderedmultidict-1.0.1 redo-3.0.0 simplejson-3.19.3 twisted-24.10.0 zope-interface-7.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "7ac85138e27f44088c34488023483d2a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install causal_conv1d==1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrfckL-P4geL",
        "outputId": "ab0e44a5-2990-47f2-a468-195164a3ce14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mamba-ssm==1.2.0.post1\n",
            "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (2.1.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm==1.2.0.post1) (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm==1.2.0.post1) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm==1.2.0.post1) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm==1.2.0.post1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm==1.2.0.post1) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=146670262 sha256=d9ceab70d6a454cdc304428c92eb9cca730b5f200192fd8a73327728b666c84a\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: mamba-ssm\n",
            "Successfully installed mamba-ssm-1.2.0.post1\n"
          ]
        }
      ],
      "source": [
        "pip install mamba-ssm==1.2.0.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbLtibVIbPA5",
        "outputId": "29a06bf2-1040-4e9a-ebd3-c033efd960d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sweep default2024-11-17-04-29-05 with 12 configs\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoradi-arghavan\u001b[0m (\u001b[33mllms_argh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_042905-m67elgv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/m67elgv5\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:22<00:00, 35.63it/s, loss=6.24]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 315.13it/s, valid/loss=6.24, valid/accuracy=0.00224, valid/input_seq_len/accuracy-64=0.00246, valid/input_seq_len/accuracy-128=0.00191, valid/input_seq_len/accuracy-256=0.002, valid/input_seq_len/accuracy-512=0.00214]\n",
            "Train Epoch 1/20: 100% 785/785 [00:19<00:00, 39.88it/s, loss=6.24]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 256.95it/s, valid/loss=6.24, valid/accuracy=0.00231, valid/input_seq_len/accuracy-64=0.00256, valid/input_seq_len/accuracy-128=0.002, valid/input_seq_len/accuracy-256=0.00195, valid/input_seq_len/accuracy-512=0.0022]\n",
            "Train Epoch 2/20: 100% 785/785 [00:19<00:00, 39.41it/s, loss=6.11]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 330.80it/s, valid/loss=7.21, valid/accuracy=0.00477, valid/input_seq_len/accuracy-64=0.00302, valid/input_seq_len/accuracy-128=0.00953, valid/input_seq_len/accuracy-256=0.00622, valid/input_seq_len/accuracy-512=0.00384]\n",
            "Train Epoch 3/20: 100% 785/785 [00:19<00:00, 39.30it/s, loss=6.09]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 319.17it/s, valid/loss=6.37, valid/accuracy=0.00566, valid/input_seq_len/accuracy-64=0.00392, valid/input_seq_len/accuracy-128=0.0113, valid/input_seq_len/accuracy-256=0.00695, valid/input_seq_len/accuracy-512=0.00393]\n",
            "Train Epoch 4/20: 100% 785/785 [00:19<00:00, 39.37it/s, loss=6.08]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 338.74it/s, valid/loss=6.48, valid/accuracy=0.00572, valid/input_seq_len/accuracy-64=0.0044, valid/input_seq_len/accuracy-128=0.00994, valid/input_seq_len/accuracy-256=0.00722, valid/input_seq_len/accuracy-512=0.00399]\n",
            "Train Epoch 5/20: 100% 785/785 [00:20<00:00, 38.66it/s, loss=6.07]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 335.85it/s, valid/loss=6.28, valid/accuracy=0.00657, valid/input_seq_len/accuracy-64=0.00556, valid/input_seq_len/accuracy-128=0.0116, valid/input_seq_len/accuracy-256=0.00692, valid/input_seq_len/accuracy-512=0.00426]\n",
            "Train Epoch 6/20: 100% 785/785 [00:20<00:00, 38.74it/s, loss=6.07]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 242.77it/s, valid/loss=6.28, valid/accuracy=0.00704, valid/input_seq_len/accuracy-64=0.0065, valid/input_seq_len/accuracy-128=0.0115, valid/input_seq_len/accuracy-256=0.00722, valid/input_seq_len/accuracy-512=0.00401]\n",
            "Train Epoch 7/20: 100% 785/785 [00:20<00:00, 38.63it/s, loss=6.06]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 330.47it/s, valid/loss=6.37, valid/accuracy=0.00634, valid/input_seq_len/accuracy-64=0.00515, valid/input_seq_len/accuracy-128=0.0113, valid/input_seq_len/accuracy-256=0.00725, valid/input_seq_len/accuracy-512=0.00409]\n",
            "Train Epoch 8/20: 100% 785/785 [00:20<00:00, 38.05it/s, loss=6.06]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 329.25it/s, valid/loss=6.25, valid/accuracy=0.00792, valid/input_seq_len/accuracy-64=0.00775, valid/input_seq_len/accuracy-128=0.013, valid/input_seq_len/accuracy-256=0.00713, valid/input_seq_len/accuracy-512=0.00416]\n",
            "Train Epoch 9/20: 100% 785/785 [00:20<00:00, 38.12it/s, loss=6.06]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 261.85it/s, valid/loss=6.38, valid/accuracy=0.00868, valid/input_seq_len/accuracy-64=0.00927, valid/input_seq_len/accuracy-128=0.0131, valid/input_seq_len/accuracy-256=0.00692, valid/input_seq_len/accuracy-512=0.00421]\n",
            "Train Epoch 10/20: 100% 785/785 [00:20<00:00, 38.06it/s, loss=6.07]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 337.19it/s, valid/loss=6.26, valid/accuracy=0.00851, valid/input_seq_len/accuracy-64=0.009, valid/input_seq_len/accuracy-128=0.0131, valid/input_seq_len/accuracy-256=0.00673, valid/input_seq_len/accuracy-512=0.00421]\n",
            "Train Epoch 11/20: 100% 785/785 [00:20<00:00, 37.68it/s, loss=6.06]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 326.88it/s, valid/loss=6.51, valid/accuracy=0.00978, valid/input_seq_len/accuracy-64=0.0115, valid/input_seq_len/accuracy-128=0.0129, valid/input_seq_len/accuracy-256=0.00697, valid/input_seq_len/accuracy-512=0.00424]\n",
            "Train Epoch 12/20: 100% 785/785 [00:20<00:00, 37.86it/s, loss=6.07]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 333.13it/s, valid/loss=6.17, valid/accuracy=0.0115, valid/input_seq_len/accuracy-64=0.0148, valid/input_seq_len/accuracy-128=0.0136, valid/input_seq_len/accuracy-256=0.00695, valid/input_seq_len/accuracy-512=0.00419]\n",
            "Train Epoch 13/20: 100% 785/785 [00:20<00:00, 38.03it/s, loss=6.06]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 322.65it/s, valid/loss=6.32, valid/accuracy=0.0198, valid/input_seq_len/accuracy-64=0.0311, valid/input_seq_len/accuracy-128=0.0138, valid/input_seq_len/accuracy-256=0.0073, valid/input_seq_len/accuracy-512=0.00434]\n",
            "Train Epoch 14/20: 100% 785/785 [00:20<00:00, 37.70it/s, loss=6.06]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 335.68it/s, valid/loss=5.77, valid/accuracy=0.0309, valid/input_seq_len/accuracy-64=0.0533, valid/input_seq_len/accuracy-128=0.0139, valid/input_seq_len/accuracy-256=0.00741, valid/input_seq_len/accuracy-512=0.00431]\n",
            "Train Epoch 15/20: 100% 785/785 [00:20<00:00, 37.82it/s, loss=6.07]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 337.98it/s, valid/loss=5.67, valid/accuracy=0.0388, valid/input_seq_len/accuracy-64=0.0692, valid/input_seq_len/accuracy-128=0.0138, valid/input_seq_len/accuracy-256=0.00739, valid/input_seq_len/accuracy-512=0.00429]\n",
            "Train Epoch 16/20: 100% 785/785 [00:20<00:00, 38.00it/s, loss=6.07]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 264.32it/s, valid/loss=5.58, valid/accuracy=0.0439, valid/input_seq_len/accuracy-64=0.0792, valid/input_seq_len/accuracy-128=0.0141, valid/input_seq_len/accuracy-256=0.00737, valid/input_seq_len/accuracy-512=0.00422]\n",
            "Train Epoch 17/20: 100% 785/785 [00:20<00:00, 37.79it/s, loss=6.07]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 337.28it/s, valid/loss=5.51, valid/accuracy=0.049, valid/input_seq_len/accuracy-64=0.0895, valid/input_seq_len/accuracy-128=0.014, valid/input_seq_len/accuracy-256=0.00733, valid/input_seq_len/accuracy-512=0.00413]\n",
            "Train Epoch 18/20: 100% 785/785 [00:20<00:00, 37.80it/s, loss=6.07]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 337.17it/s, valid/loss=5.48, valid/accuracy=0.0491, valid/input_seq_len/accuracy-64=0.0897, valid/input_seq_len/accuracy-128=0.0142, valid/input_seq_len/accuracy-256=0.00717, valid/input_seq_len/accuracy-512=0.00423]\n",
            "Train Epoch 19/20: 100% 785/785 [00:20<00:00, 38.03it/s, loss=6.07]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 246.98it/s, valid/loss=5.48, valid/accuracy=0.0481, valid/input_seq_len/accuracy-64=0.0878, valid/input_seq_len/accuracy-128=0.014, valid/input_seq_len/accuracy-256=0.00709, valid/input_seq_len/accuracy-512=0.00427]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █████▇▇▇▇▇▃▇██▇▂▅▇▇█▇▇▇▇▅▇▅▇▇█▁▁▅▆█▆▁▇▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss █▇▇▇▇▇▆▆▄▅▇▂▆▇▅▆▇▇▇▇▂▄▆▆▇▄▄▆▇▇▄▇▇▄▇▁▄▇▄▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▁▁▂▂▂▂▂▂▂▂▂▂▄▅▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▅▆▆▇▆▆▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▆▇█▇███▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▆▇▇█▇▇▇████████▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▁▁▁▁▁▁▁▁▂▂▂▂▃▅▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▄▄█▅▅▄▄▅▄▅▄▅▄▄▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 131072\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 16384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 6.07228\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 6.07228\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.04811\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.014\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.00709\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00427\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.08777\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 5.47676\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/m67elgv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_042905-m67elgv5/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_043624-p7tendw3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/p7tendw3\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0031622776601683794\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:20<00:00, 37.91it/s, loss=6]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 251.52it/s, valid/loss=6.21, valid/accuracy=0.0255, valid/input_seq_len/accuracy-64=0.0382, valid/input_seq_len/accuracy-128=0.0208, valid/input_seq_len/accuracy-256=0.0124, valid/input_seq_len/accuracy-512=0.00545]\n",
            "Train Epoch 1/20: 100% 785/785 [00:20<00:00, 37.64it/s, loss=5.93]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 330.19it/s, valid/loss=5.57, valid/accuracy=0.0662, valid/input_seq_len/accuracy-64=0.118, valid/input_seq_len/accuracy-128=0.0243, valid/input_seq_len/accuracy-256=0.0131, valid/input_seq_len/accuracy-512=0.00519]\n",
            "Train Epoch 2/20: 100% 785/785 [00:20<00:00, 37.69it/s, loss=5.92]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 328.76it/s, valid/loss=5.81, valid/accuracy=0.0381, valid/input_seq_len/accuracy-64=0.0625, valid/input_seq_len/accuracy-128=0.0225, valid/input_seq_len/accuracy-256=0.013, valid/input_seq_len/accuracy-512=0.00544]\n",
            "Train Epoch 3/20: 100% 785/785 [00:20<00:00, 38.01it/s, loss=5.91]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 238.79it/s, valid/loss=6.87, valid/accuracy=0.0333, valid/input_seq_len/accuracy-64=0.0533, valid/input_seq_len/accuracy-128=0.0198, valid/input_seq_len/accuracy-256=0.014, valid/input_seq_len/accuracy-512=0.006]\n",
            "Train Epoch 4/20: 100% 785/785 [00:20<00:00, 38.01it/s, loss=5.91]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 332.57it/s, valid/loss=6.27, valid/accuracy=0.044, valid/input_seq_len/accuracy-64=0.0731, valid/input_seq_len/accuracy-128=0.0247, valid/input_seq_len/accuracy-256=0.0141, valid/input_seq_len/accuracy-512=0.00566]\n",
            "Train Epoch 5/20: 100% 785/785 [00:20<00:00, 37.67it/s, loss=5.91]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 330.42it/s, valid/loss=5.41, valid/accuracy=0.0799, valid/input_seq_len/accuracy-64=0.144, valid/input_seq_len/accuracy-128=0.0278, valid/input_seq_len/accuracy-256=0.0137, valid/input_seq_len/accuracy-512=0.00673]\n",
            "Train Epoch 6/20: 100% 785/785 [00:20<00:00, 37.90it/s, loss=5.9]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 271.86it/s, valid/loss=5.54, valid/accuracy=0.0804, valid/input_seq_len/accuracy-64=0.145, valid/input_seq_len/accuracy-128=0.0276, valid/input_seq_len/accuracy-256=0.0136, valid/input_seq_len/accuracy-512=0.00662]\n",
            "Train Epoch 7/20: 100% 785/785 [00:20<00:00, 37.98it/s, loss=5.88]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 335.46it/s, valid/loss=5.53, valid/accuracy=0.0661, valid/input_seq_len/accuracy-64=0.115, valid/input_seq_len/accuracy-128=0.0294, valid/input_seq_len/accuracy-256=0.0147, valid/input_seq_len/accuracy-512=0.00702]\n",
            "Train Epoch 8/20: 100% 785/785 [00:20<00:00, 37.52it/s, loss=5.87]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 330.22it/s, valid/loss=6.94, valid/accuracy=0.0174, valid/input_seq_len/accuracy-64=0.0211, valid/input_seq_len/accuracy-128=0.02, valid/input_seq_len/accuracy-256=0.0155, valid/input_seq_len/accuracy-512=0.00581]\n",
            "Train Epoch 9/20: 100% 785/785 [00:20<00:00, 37.82it/s, loss=5.87]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 332.15it/s, valid/loss=5.67, valid/accuracy=0.0555, valid/input_seq_len/accuracy-64=0.0943, valid/input_seq_len/accuracy-128=0.029, valid/input_seq_len/accuracy-256=0.0152, valid/input_seq_len/accuracy-512=0.00594]\n",
            "Train Epoch 10/20: 100% 785/785 [00:20<00:00, 38.03it/s, loss=5.86]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 308.68it/s, valid/loss=5.07, valid/accuracy=0.0795, valid/input_seq_len/accuracy-64=0.142, valid/input_seq_len/accuracy-128=0.0291, valid/input_seq_len/accuracy-256=0.0153, valid/input_seq_len/accuracy-512=0.00627]\n",
            "Train Epoch 11/20: 100% 785/785 [00:20<00:00, 37.62it/s, loss=5.86]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 335.35it/s, valid/loss=5.28, valid/accuracy=0.0786, valid/input_seq_len/accuracy-64=0.14, valid/input_seq_len/accuracy-128=0.0296, valid/input_seq_len/accuracy-256=0.0155, valid/input_seq_len/accuracy-512=0.00692]\n",
            "Train Epoch 12/20: 100% 785/785 [00:20<00:00, 37.91it/s, loss=5.86]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 328.45it/s, valid/loss=5.13, valid/accuracy=0.082, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.0295, valid/input_seq_len/accuracy-256=0.0155, valid/input_seq_len/accuracy-512=0.00706]\n",
            "Train Epoch 13/20: 100% 785/785 [00:20<00:00, 38.21it/s, loss=5.85]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 258.45it/s, valid/loss=5.1, valid/accuracy=0.0761, valid/input_seq_len/accuracy-64=0.135, valid/input_seq_len/accuracy-128=0.0296, valid/input_seq_len/accuracy-256=0.0157, valid/input_seq_len/accuracy-512=0.00671]\n",
            "Train Epoch 14/20: 100% 785/785 [00:20<00:00, 37.96it/s, loss=5.85]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 332.46it/s, valid/loss=4.97, valid/accuracy=0.0801, valid/input_seq_len/accuracy-64=0.143, valid/input_seq_len/accuracy-128=0.03, valid/input_seq_len/accuracy-256=0.0156, valid/input_seq_len/accuracy-512=0.00683]\n",
            "Train Epoch 15/20: 100% 785/785 [00:20<00:00, 37.89it/s, loss=5.84]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 330.38it/s, valid/loss=4.92, valid/accuracy=0.0813, valid/input_seq_len/accuracy-64=0.145, valid/input_seq_len/accuracy-128=0.0297, valid/input_seq_len/accuracy-256=0.0158, valid/input_seq_len/accuracy-512=0.0067]\n",
            "Train Epoch 16/20: 100% 785/785 [00:20<00:00, 38.13it/s, loss=5.84]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 252.20it/s, valid/loss=4.9, valid/accuracy=0.0814, valid/input_seq_len/accuracy-64=0.145, valid/input_seq_len/accuracy-128=0.0298, valid/input_seq_len/accuracy-256=0.0164, valid/input_seq_len/accuracy-512=0.0068]\n",
            "Train Epoch 17/20: 100% 785/785 [00:20<00:00, 37.94it/s, loss=5.84]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 331.49it/s, valid/loss=4.89, valid/accuracy=0.0807, valid/input_seq_len/accuracy-64=0.144, valid/input_seq_len/accuracy-128=0.03, valid/input_seq_len/accuracy-256=0.0162, valid/input_seq_len/accuracy-512=0.00681]\n",
            "Train Epoch 18/20: 100% 785/785 [00:20<00:00, 37.79it/s, loss=5.84]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 334.43it/s, valid/loss=4.89, valid/accuracy=0.0804, valid/input_seq_len/accuracy-64=0.143, valid/input_seq_len/accuracy-128=0.0298, valid/input_seq_len/accuracy-256=0.0162, valid/input_seq_len/accuracy-512=0.00677]\n",
            "Train Epoch 19/20: 100% 785/785 [00:20<00:00, 38.05it/s, loss=5.84]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 240.73it/s, valid/loss=4.89, valid/accuracy=0.0789, valid/input_seq_len/accuracy-64=0.14, valid/input_seq_len/accuracy-128=0.0289, valid/input_seq_len/accuracy-256=0.0162, valid/input_seq_len/accuracy-512=0.00686]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ▃██▅▇████▂▅█▅▂▄▄▇█▆▇▁█▁▁▁▄█▁▄▆█▁▁▄▆█▆▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ▃▆▇█▇▃▂█▇█▆▅██▂█▂▆▇█▇▁▇▂▄▇▁██▁▄▇▁▄█▆▁▇▄▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▂▆▃▃▄██▆▁▅███▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▂▄▃▁▄▆▆█▁▇▇████████▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▂▂▄▄▃▃▅▆▆▆▆▆▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▂▁▂▄▃▇▆█▃▄▅▇█▇▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▂▆▃▃▄██▆▁▅███▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▆▃▄█▆▃▃▃█▄▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 131072\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 16384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 5.83625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 5.83625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.0789\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.02894\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.01617\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00686\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.14048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 4.88515\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/p7tendw3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_043624-p7tendw3/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_044347-6v6slhzq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/6v6slhzq\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:20<00:00, 37.97it/s, loss=6.15]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 251.82it/s, valid/loss=6.35, valid/accuracy=0.0099, valid/input_seq_len/accuracy-64=0.0139, valid/input_seq_len/accuracy-128=0.00844, valid/input_seq_len/accuracy-256=0.0058, valid/input_seq_len/accuracy-512=0.00334]\n",
            "Train Epoch 1/20: 100% 785/785 [00:20<00:00, 37.85it/s, loss=6.06]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 328.90it/s, valid/loss=5.78, valid/accuracy=0.0385, valid/input_seq_len/accuracy-64=0.0676, valid/input_seq_len/accuracy-128=0.0154, valid/input_seq_len/accuracy-256=0.008, valid/input_seq_len/accuracy-512=0.00473]\n",
            "Train Epoch 2/20: 100% 785/785 [00:20<00:00, 37.88it/s, loss=6]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 335.16it/s, valid/loss=5.92, valid/accuracy=0.0566, valid/input_seq_len/accuracy-64=0.102, valid/input_seq_len/accuracy-128=0.0185, valid/input_seq_len/accuracy-256=0.0105, valid/input_seq_len/accuracy-512=0.00487]\n",
            "Train Epoch 3/20: 100% 785/785 [00:20<00:00, 38.06it/s, loss=5.96]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 238.27it/s, valid/loss=5.95, valid/accuracy=0.0244, valid/input_seq_len/accuracy-64=0.0373, valid/input_seq_len/accuracy-128=0.0187, valid/input_seq_len/accuracy-256=0.0115, valid/input_seq_len/accuracy-512=0.00466]\n",
            "Train Epoch 4/20: 100% 785/785 [00:20<00:00, 38.08it/s, loss=5.94]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 326.76it/s, valid/loss=6.19, valid/accuracy=0.0138, valid/input_seq_len/accuracy-64=0.0157, valid/input_seq_len/accuracy-128=0.018, valid/input_seq_len/accuracy-256=0.0126, valid/input_seq_len/accuracy-512=0.00507]\n",
            "Train Epoch 5/20: 100% 785/785 [00:21<00:00, 37.35it/s, loss=5.92]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 334.68it/s, valid/loss=6.55, valid/accuracy=0.0321, valid/input_seq_len/accuracy-64=0.0505, valid/input_seq_len/accuracy-128=0.0216, valid/input_seq_len/accuracy-256=0.0141, valid/input_seq_len/accuracy-512=0.00565]\n",
            "Train Epoch 6/20: 100% 785/785 [00:20<00:00, 37.56it/s, loss=5.91]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 294.97it/s, valid/loss=6.36, valid/accuracy=0.0148, valid/input_seq_len/accuracy-64=0.0183, valid/input_seq_len/accuracy-128=0.0145, valid/input_seq_len/accuracy-256=0.0137, valid/input_seq_len/accuracy-512=0.00543]\n",
            "Train Epoch 7/20: 100% 785/785 [00:20<00:00, 37.76it/s, loss=5.92]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 328.58it/s, valid/loss=6.48, valid/accuracy=0.0255, valid/input_seq_len/accuracy-64=0.0385, valid/input_seq_len/accuracy-128=0.0216, valid/input_seq_len/accuracy-256=0.012, valid/input_seq_len/accuracy-512=0.00416]\n",
            "Train Epoch 8/20: 100% 785/785 [00:21<00:00, 37.36it/s, loss=5.89]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 325.39it/s, valid/loss=6.17, valid/accuracy=0.0368, valid/input_seq_len/accuracy-64=0.06, valid/input_seq_len/accuracy-128=0.0219, valid/input_seq_len/accuracy-256=0.014, valid/input_seq_len/accuracy-512=0.00517]\n",
            "Train Epoch 9/20: 100% 785/785 [00:20<00:00, 37.61it/s, loss=5.88]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 332.21it/s, valid/loss=6.54, valid/accuracy=0.0124, valid/input_seq_len/accuracy-64=0.0138, valid/input_seq_len/accuracy-128=0.0134, valid/input_seq_len/accuracy-256=0.0146, valid/input_seq_len/accuracy-512=0.00523]\n",
            "Train Epoch 10/20: 100% 785/785 [00:20<00:00, 37.68it/s, loss=5.88]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 287.88it/s, valid/loss=6.16, valid/accuracy=0.029, valid/input_seq_len/accuracy-64=0.0445, valid/input_seq_len/accuracy-128=0.0196, valid/input_seq_len/accuracy-256=0.015, valid/input_seq_len/accuracy-512=0.00586]\n",
            "Train Epoch 11/20: 100% 785/785 [00:21<00:00, 37.34it/s, loss=5.87]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 335.31it/s, valid/loss=6.71, valid/accuracy=0.0228, valid/input_seq_len/accuracy-64=0.0336, valid/input_seq_len/accuracy-128=0.0163, valid/input_seq_len/accuracy-256=0.0146, valid/input_seq_len/accuracy-512=0.00552]\n",
            "Train Epoch 12/20: 100% 785/785 [00:20<00:00, 37.51it/s, loss=5.86]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 328.59it/s, valid/loss=6.13, valid/accuracy=0.0292, valid/input_seq_len/accuracy-64=0.0446, valid/input_seq_len/accuracy-128=0.0211, valid/input_seq_len/accuracy-256=0.015, valid/input_seq_len/accuracy-512=0.00555]\n",
            "Train Epoch 13/20: 100% 785/785 [00:20<00:00, 37.77it/s, loss=5.86]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 248.48it/s, valid/loss=6.65, valid/accuracy=0.013, valid/input_seq_len/accuracy-64=0.0169, valid/input_seq_len/accuracy-128=0.00744, valid/input_seq_len/accuracy-256=0.0143, valid/input_seq_len/accuracy-512=0.00552]\n",
            "Train Epoch 14/20: 100% 785/785 [00:20<00:00, 37.70it/s, loss=5.85]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 333.01it/s, valid/loss=5.57, valid/accuracy=0.0669, valid/input_seq_len/accuracy-64=0.119, valid/input_seq_len/accuracy-128=0.0231, valid/input_seq_len/accuracy-256=0.0149, valid/input_seq_len/accuracy-512=0.0065]\n",
            "Train Epoch 15/20: 100% 785/785 [00:20<00:00, 37.42it/s, loss=5.85]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 325.77it/s, valid/loss=5.17, valid/accuracy=0.0742, valid/input_seq_len/accuracy-64=0.133, valid/input_seq_len/accuracy-128=0.0262, valid/input_seq_len/accuracy-256=0.0149, valid/input_seq_len/accuracy-512=0.00657]\n",
            "Train Epoch 16/20: 100% 785/785 [00:20<00:00, 37.88it/s, loss=5.85]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 234.40it/s, valid/loss=5.23, valid/accuracy=0.076, valid/input_seq_len/accuracy-64=0.136, valid/input_seq_len/accuracy-128=0.0265, valid/input_seq_len/accuracy-256=0.015, valid/input_seq_len/accuracy-512=0.00753]\n",
            "Train Epoch 17/20: 100% 785/785 [00:20<00:00, 37.98it/s, loss=5.84]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 333.55it/s, valid/loss=5.01, valid/accuracy=0.0818, valid/input_seq_len/accuracy-64=0.146, valid/input_seq_len/accuracy-128=0.0286, valid/input_seq_len/accuracy-256=0.0152, valid/input_seq_len/accuracy-512=0.00766]\n",
            "Train Epoch 18/20: 100% 785/785 [00:20<00:00, 37.60it/s, loss=5.84]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 334.85it/s, valid/loss=4.96, valid/accuracy=0.0824, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.0297, valid/input_seq_len/accuracy-256=0.0152, valid/input_seq_len/accuracy-512=0.00752]\n",
            "Train Epoch 19/20: 100% 785/785 [00:20<00:00, 37.84it/s, loss=5.84]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 302.09it/s, valid/loss=4.93, valid/accuracy=0.0792, valid/input_seq_len/accuracy-64=0.141, valid/input_seq_len/accuracy-128=0.0294, valid/input_seq_len/accuracy-256=0.0148, valid/input_seq_len/accuracy-512=0.00768]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █▆█▄▆▅▇▂▅▃▅▇▇▇▇▇▇▇▂▁▆██▇▇▅▂▁▁▆▆▇▇▄▆▁▇▁▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ████▆██▄██▅▅▂▅▃▆▇██▅▇███▄▆▁▁▄▆▇▇█▁▆▁▄▄▄▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▄▆▂▁▃▁▃▄▁▃▂▃▁▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▄▄▅▄▅▃▅▆▃▅▄▅▁▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▃▄▅▆▇▇▆▇████▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▃▃▃▄▅▄▂▄▄▅▅▅▅▆▆████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▄▆▂▁▃▁▂▃▁▃▂▃▁▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▇▄▅▅▆▇▇▇▆▇▆█▆█▄▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 131072\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 16384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 5.8419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 5.8419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.07924\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.02941\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.01481\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.14119\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 4.93348\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/6v6slhzq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_044347-6v6slhzq/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_045111-67qxg9ma\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/67qxg9ma\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.03162277660168379\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:20<00:00, 37.85it/s, loss=6.25]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 235.68it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 1/20: 100% 785/785 [00:20<00:00, 37.82it/s, loss=6.25]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 330.22it/s, valid/loss=6.25, valid/accuracy=0.00158, valid/input_seq_len/accuracy-64=0.000979, valid/input_seq_len/accuracy-128=0.00231, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.00195]\n",
            "Train Epoch 2/20: 100% 785/785 [00:20<00:00, 37.65it/s, loss=6.27]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 331.39it/s, valid/loss=6.27, valid/accuracy=0.002, valid/input_seq_len/accuracy-64=0.002, valid/input_seq_len/accuracy-128=0.00197, valid/input_seq_len/accuracy-256=0.00225, valid/input_seq_len/accuracy-512=0.00177]\n",
            "Train Epoch 3/20: 100% 785/785 [00:20<00:00, 37.80it/s, loss=6.26]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 289.84it/s, valid/loss=6.25, valid/accuracy=0.00162, valid/input_seq_len/accuracy-64=0.00102, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00228, valid/input_seq_len/accuracy-512=0.00202]\n",
            "Train Epoch 4/20: 100% 785/785 [00:20<00:00, 38.10it/s, loss=6.26]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 328.96it/s, valid/loss=6.25, valid/accuracy=0.00183, valid/input_seq_len/accuracy-64=0.00158, valid/input_seq_len/accuracy-128=0.00225, valid/input_seq_len/accuracy-256=0.00192, valid/input_seq_len/accuracy-512=0.00203]\n",
            "Train Epoch 5/20: 100% 785/785 [00:20<00:00, 37.61it/s, loss=6.26]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 332.27it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 6/20: 100% 785/785 [00:20<00:00, 37.88it/s, loss=6.26]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 330.08it/s, valid/loss=6.25, valid/accuracy=0.00162, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.00198]\n",
            "Train Epoch 7/20: 100% 785/785 [00:20<00:00, 38.05it/s, loss=6.26]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 328.04it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 8/20: 100% 785/785 [00:20<00:00, 37.62it/s, loss=6.25]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 330.58it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 9/20: 100% 785/785 [00:20<00:00, 37.86it/s, loss=6.25]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 332.25it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 10/20: 100% 785/785 [00:20<00:00, 38.03it/s, loss=6.22]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 299.07it/s, valid/loss=6.26, valid/accuracy=0.00239, valid/input_seq_len/accuracy-64=0.00221, valid/input_seq_len/accuracy-128=0.00278, valid/input_seq_len/accuracy-256=0.00275, valid/input_seq_len/accuracy-512=0.00218]\n",
            "Train Epoch 11/20: 100% 785/785 [00:20<00:00, 37.54it/s, loss=6.01]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 328.35it/s, valid/loss=6.44, valid/accuracy=0.0324, valid/input_seq_len/accuracy-64=0.0522, valid/input_seq_len/accuracy-128=0.0209, valid/input_seq_len/accuracy-256=0.0114, valid/input_seq_len/accuracy-512=0.00568]\n",
            "Train Epoch 12/20: 100% 785/785 [00:20<00:00, 37.66it/s, loss=5.95]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 320.31it/s, valid/loss=6.73, valid/accuracy=0.0168, valid/input_seq_len/accuracy-64=0.0222, valid/input_seq_len/accuracy-128=0.0141, valid/input_seq_len/accuracy-256=0.015, valid/input_seq_len/accuracy-512=0.00511]\n",
            "Train Epoch 13/20: 100% 785/785 [00:20<00:00, 38.03it/s, loss=5.92]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 257.19it/s, valid/loss=6.82, valid/accuracy=0.0325, valid/input_seq_len/accuracy-64=0.0495, valid/input_seq_len/accuracy-128=0.0286, valid/input_seq_len/accuracy-256=0.0126, valid/input_seq_len/accuracy-512=0.00534]\n",
            "Train Epoch 14/20: 100% 785/785 [00:20<00:00, 37.70it/s, loss=5.86]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 340.20it/s, valid/loss=5.35, valid/accuracy=0.0777, valid/input_seq_len/accuracy-64=0.139, valid/input_seq_len/accuracy-128=0.0286, valid/input_seq_len/accuracy-256=0.0152, valid/input_seq_len/accuracy-512=0.00588]\n",
            "Train Epoch 15/20: 100% 785/785 [00:20<00:00, 37.74it/s, loss=5.85]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 334.44it/s, valid/loss=6.57, valid/accuracy=0.0315, valid/input_seq_len/accuracy-64=0.0463, valid/input_seq_len/accuracy-128=0.0275, valid/input_seq_len/accuracy-256=0.0157, valid/input_seq_len/accuracy-512=0.00695]\n",
            "Train Epoch 16/20: 100% 785/785 [00:20<00:00, 37.97it/s, loss=5.85]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 254.48it/s, valid/loss=6, valid/accuracy=0.0393, valid/input_seq_len/accuracy-64=0.0608, valid/input_seq_len/accuracy-128=0.0304, valid/input_seq_len/accuracy-256=0.0156, valid/input_seq_len/accuracy-512=0.00719]\n",
            "Train Epoch 17/20: 100% 785/785 [00:20<00:00, 37.94it/s, loss=5.84]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 336.04it/s, valid/loss=5.3, valid/accuracy=0.0652, valid/input_seq_len/accuracy-64=0.113, valid/input_seq_len/accuracy-128=0.0301, valid/input_seq_len/accuracy-256=0.0161, valid/input_seq_len/accuracy-512=0.00714]\n",
            "Train Epoch 18/20: 100% 785/785 [00:20<00:00, 37.67it/s, loss=5.83]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 327.87it/s, valid/loss=4.96, valid/accuracy=0.081, valid/input_seq_len/accuracy-64=0.144, valid/input_seq_len/accuracy-128=0.0313, valid/input_seq_len/accuracy-256=0.0159, valid/input_seq_len/accuracy-512=0.00741]\n",
            "Train Epoch 19/20: 100% 785/785 [00:20<00:00, 37.91it/s, loss=5.83]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 241.61it/s, valid/loss=4.87, valid/accuracy=0.0823, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.0302, valid/input_seq_len/accuracy-256=0.0156, valid/input_seq_len/accuracy-512=0.00767]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ████████████████████████▆▅▇▆▆▇▇▇▇▆▆▅▁▁▃▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ███████████████████████▇▆▇▆▂▁▁▇▇▇▇▂▄▇▁▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▁▁▁▁▁▁▁▁▁▁▄▂▄█▄▄▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▁▁▁▁▁▁▁▁▁▆▄▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▁▁▁▁▁▁▁▁▁▆▇▆██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▁▁▁▁▁▁▁▁▁▆▅▅▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▁▁▁▁▁▁▁▁▁▁▃▂▃█▃▄▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▆▆▆▆▆▆▆▆▆▆▆▇██▃▇▅▃▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 131072\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 16384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 5.83356\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 5.83356\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.08226\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.03025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.01562\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00767\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.14667\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 4.87379\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/67qxg9ma\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_045111-67qxg9ma/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_045833-2kw5dj69\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/2kw5dj69\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:41<00:00, 18.84it/s, loss=6.24]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 294.80it/s, valid/loss=6.24, valid/accuracy=0.00225, valid/input_seq_len/accuracy-64=0.00248, valid/input_seq_len/accuracy-128=0.00187, valid/input_seq_len/accuracy-256=0.00203, valid/input_seq_len/accuracy-512=0.00216]\n",
            "Train Epoch 1/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=5.8]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 297.92it/s, valid/loss=7.98, valid/accuracy=0.0191, valid/input_seq_len/accuracy-64=0.0254, valid/input_seq_len/accuracy-128=0.0175, valid/input_seq_len/accuracy-256=0.0145, valid/input_seq_len/accuracy-512=0.00609]\n",
            "Train Epoch 2/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=5.77]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 297.95it/s, valid/loss=7.01, valid/accuracy=0.0181, valid/input_seq_len/accuracy-64=0.0196, valid/input_seq_len/accuracy-128=0.0287, valid/input_seq_len/accuracy-256=0.0147, valid/input_seq_len/accuracy-512=0.0063]\n",
            "Train Epoch 3/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.77]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 295.60it/s, valid/loss=6.88, valid/accuracy=0.0192, valid/input_seq_len/accuracy-64=0.0216, valid/input_seq_len/accuracy-128=0.0292, valid/input_seq_len/accuracy-256=0.0143, valid/input_seq_len/accuracy-512=0.00673]\n",
            "Train Epoch 4/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.76]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 297.86it/s, valid/loss=6.19, valid/accuracy=0.0215, valid/input_seq_len/accuracy-64=0.0265, valid/input_seq_len/accuracy-128=0.0282, valid/input_seq_len/accuracy-256=0.0144, valid/input_seq_len/accuracy-512=0.00688]\n",
            "Train Epoch 5/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.75]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 294.27it/s, valid/loss=6.76, valid/accuracy=0.0193, valid/input_seq_len/accuracy-64=0.0221, valid/input_seq_len/accuracy-128=0.028, valid/input_seq_len/accuracy-256=0.0147, valid/input_seq_len/accuracy-512=0.00694]\n",
            "Train Epoch 6/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.74]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 296.34it/s, valid/loss=6.5, valid/accuracy=0.0205, valid/input_seq_len/accuracy-64=0.0243, valid/input_seq_len/accuracy-128=0.0283, valid/input_seq_len/accuracy-256=0.0149, valid/input_seq_len/accuracy-512=0.00702]\n",
            "Train Epoch 7/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.73]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 298.46it/s, valid/loss=6.04, valid/accuracy=0.0181, valid/input_seq_len/accuracy-64=0.0203, valid/input_seq_len/accuracy-128=0.0252, valid/input_seq_len/accuracy-256=0.0154, valid/input_seq_len/accuracy-512=0.00718]\n",
            "Train Epoch 8/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=5.72]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 297.76it/s, valid/loss=6.45, valid/accuracy=0.0215, valid/input_seq_len/accuracy-64=0.0259, valid/input_seq_len/accuracy-128=0.0287, valid/input_seq_len/accuracy-256=0.0156, valid/input_seq_len/accuracy-512=0.00715]\n",
            "Train Epoch 9/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=5.71]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 296.08it/s, valid/loss=6.08, valid/accuracy=0.0197, valid/input_seq_len/accuracy-64=0.0228, valid/input_seq_len/accuracy-128=0.0262, valid/input_seq_len/accuracy-256=0.0161, valid/input_seq_len/accuracy-512=0.00742]\n",
            "Train Epoch 10/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=5.71]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 264.54it/s, valid/loss=6.19, valid/accuracy=0.0222, valid/input_seq_len/accuracy-64=0.0274, valid/input_seq_len/accuracy-128=0.0276, valid/input_seq_len/accuracy-256=0.0161, valid/input_seq_len/accuracy-512=0.00748]\n",
            "Train Epoch 11/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=5.71]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 241.83it/s, valid/loss=6.23, valid/accuracy=0.0226, valid/input_seq_len/accuracy-64=0.0283, valid/input_seq_len/accuracy-128=0.0279, valid/input_seq_len/accuracy-256=0.0158, valid/input_seq_len/accuracy-512=0.00727]\n",
            "Train Epoch 12/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=5.71]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 223.49it/s, valid/loss=6.24, valid/accuracy=0.0232, valid/input_seq_len/accuracy-64=0.0292, valid/input_seq_len/accuracy-128=0.0289, valid/input_seq_len/accuracy-256=0.0155, valid/input_seq_len/accuracy-512=0.0073]\n",
            "Train Epoch 13/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.72]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 225.61it/s, valid/loss=5.92, valid/accuracy=0.0321, valid/input_seq_len/accuracy-64=0.0458, valid/input_seq_len/accuracy-128=0.0331, valid/input_seq_len/accuracy-256=0.0152, valid/input_seq_len/accuracy-512=0.00724]\n",
            "Train Epoch 14/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.73]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 225.92it/s, valid/loss=5.35, valid/accuracy=0.0549, valid/input_seq_len/accuracy-64=0.0917, valid/input_seq_len/accuracy-128=0.0326, valid/input_seq_len/accuracy-256=0.0147, valid/input_seq_len/accuracy-512=0.00704]\n",
            "Train Epoch 15/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.74]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 233.94it/s, valid/loss=4.85, valid/accuracy=0.0836, valid/input_seq_len/accuracy-64=0.15, valid/input_seq_len/accuracy-128=0.0312, valid/input_seq_len/accuracy-256=0.0143, valid/input_seq_len/accuracy-512=0.00684]\n",
            "Train Epoch 16/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.74]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 233.74it/s, valid/loss=4.83, valid/accuracy=0.0867, valid/input_seq_len/accuracy-64=0.156, valid/input_seq_len/accuracy-128=0.0323, valid/input_seq_len/accuracy-256=0.0143, valid/input_seq_len/accuracy-512=0.00677]\n",
            "Train Epoch 17/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=5.74]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 238.90it/s, valid/loss=4.74, valid/accuracy=0.0896, valid/input_seq_len/accuracy-64=0.162, valid/input_seq_len/accuracy-128=0.0314, valid/input_seq_len/accuracy-256=0.0141, valid/input_seq_len/accuracy-512=0.00667]\n",
            "Train Epoch 18/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=5.75]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 237.64it/s, valid/loss=4.69, valid/accuracy=0.0888, valid/input_seq_len/accuracy-64=0.161, valid/input_seq_len/accuracy-128=0.0304, valid/input_seq_len/accuracy-256=0.0141, valid/input_seq_len/accuracy-512=0.00655]\n",
            "Train Epoch 19/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=5.75]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 271.32it/s, valid/loss=4.69, valid/accuracy=0.089, valid/input_seq_len/accuracy-64=0.161, valid/input_seq_len/accuracy-128=0.0301, valid/input_seq_len/accuracy-256=0.014, valid/input_seq_len/accuracy-512=0.00664]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █▆▇▇▄▇▇▇▄▇▂▄▇▄▂▄▆▆▅▇▄▆▇▁▆▆▆▇▂▂▂▃▇▇▃▇▇▃▅▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss █▅▇▇▃▄▆▇▄▄▇▇▆▅▇▄▇▁▆▇▅▅▅▅▅▃▅▇▁▅▅▅▅▇▁▇▇▃▃▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▂▂▂▃▂▂▂▃▂▃▃▃▃▅█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▅▇▇▇▇▇▆▇▆▇▇▇█████▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▇▇▇▇▇▇███████▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▆▆▇▇▇▇███████▇▇▇▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▂▂▂▂▂▂▂▂▂▂▂▂▃▅▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▄█▆▆▄▅▅▄▅▄▄▄▄▄▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 364544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 32768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 5.74866\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 5.74866\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.08904\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.03006\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.01402\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00664\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.16117\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 4.68727\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/2kw5dj69\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_045833-2kw5dj69/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_051133-qu3gihna\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/qu3gihna\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0031622776601683794\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=6]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 228.17it/s, valid/loss=6.45, valid/accuracy=0.0261, valid/input_seq_len/accuracy-64=0.0407, valid/input_seq_len/accuracy-128=0.0205, valid/input_seq_len/accuracy-256=0.0107, valid/input_seq_len/accuracy-512=0.00349]\n",
            "Train Epoch 1/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=5.95]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 231.42it/s, valid/loss=5.74, valid/accuracy=0.0599, valid/input_seq_len/accuracy-64=0.105, valid/input_seq_len/accuracy-128=0.0252, valid/input_seq_len/accuracy-256=0.0133, valid/input_seq_len/accuracy-512=0.00545]\n",
            "Train Epoch 2/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=5.9]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 244.62it/s, valid/loss=7.22, valid/accuracy=0.0356, valid/input_seq_len/accuracy-64=0.0548, valid/input_seq_len/accuracy-128=0.0289, valid/input_seq_len/accuracy-256=0.0151, valid/input_seq_len/accuracy-512=0.00547]\n",
            "Train Epoch 3/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=5.88]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 242.11it/s, valid/loss=5.59, valid/accuracy=0.0534, valid/input_seq_len/accuracy-64=0.09, valid/input_seq_len/accuracy-128=0.0296, valid/input_seq_len/accuracy-256=0.0155, valid/input_seq_len/accuracy-512=0.00549]\n",
            "Train Epoch 4/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=5.87]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 285.18it/s, valid/loss=5.64, valid/accuracy=0.0585, valid/input_seq_len/accuracy-64=0.1, valid/input_seq_len/accuracy-128=0.0304, valid/input_seq_len/accuracy-256=0.0149, valid/input_seq_len/accuracy-512=0.00455]\n",
            "Train Epoch 5/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=5.82]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 302.86it/s, valid/loss=5.4, valid/accuracy=0.0662, valid/input_seq_len/accuracy-64=0.115, valid/input_seq_len/accuracy-128=0.0309, valid/input_seq_len/accuracy-256=0.0163, valid/input_seq_len/accuracy-512=0.00526]\n",
            "Train Epoch 6/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=5.81]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 298.34it/s, valid/loss=5.13, valid/accuracy=0.082, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.0293, valid/input_seq_len/accuracy-256=0.0169, valid/input_seq_len/accuracy-512=0.00545]\n",
            "Train Epoch 7/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=5.81]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 300.86it/s, valid/loss=5.9, valid/accuracy=0.072, valid/input_seq_len/accuracy-64=0.126, valid/input_seq_len/accuracy-128=0.0312, valid/input_seq_len/accuracy-256=0.0161, valid/input_seq_len/accuracy-512=0.00583]\n",
            "Train Epoch 8/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.79]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 302.68it/s, valid/loss=5.46, valid/accuracy=0.065, valid/input_seq_len/accuracy-64=0.115, valid/input_seq_len/accuracy-128=0.0251, valid/input_seq_len/accuracy-256=0.0159, valid/input_seq_len/accuracy-512=0.00383]\n",
            "Train Epoch 9/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=5.77]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 301.77it/s, valid/loss=5.22, valid/accuracy=0.0825, valid/input_seq_len/accuracy-64=0.148, valid/input_seq_len/accuracy-128=0.0282, valid/input_seq_len/accuracy-256=0.0166, valid/input_seq_len/accuracy-512=0.0053]\n",
            "Train Epoch 10/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=5.75]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 298.77it/s, valid/loss=4.89, valid/accuracy=0.084, valid/input_seq_len/accuracy-64=0.15, valid/input_seq_len/accuracy-128=0.0299, valid/input_seq_len/accuracy-256=0.0177, valid/input_seq_len/accuracy-512=0.00592]\n",
            "Train Epoch 11/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.75]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 300.80it/s, valid/loss=5.09, valid/accuracy=0.0853, valid/input_seq_len/accuracy-64=0.153, valid/input_seq_len/accuracy-128=0.0298, valid/input_seq_len/accuracy-256=0.0178, valid/input_seq_len/accuracy-512=0.00553]\n",
            "Train Epoch 12/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=5.74]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 304.37it/s, valid/loss=4.95, valid/accuracy=0.0865, valid/input_seq_len/accuracy-64=0.155, valid/input_seq_len/accuracy-128=0.0313, valid/input_seq_len/accuracy-256=0.0177, valid/input_seq_len/accuracy-512=0.00584]\n",
            "Train Epoch 13/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5.73]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 289.78it/s, valid/loss=4.84, valid/accuracy=0.0869, valid/input_seq_len/accuracy-64=0.155, valid/input_seq_len/accuracy-128=0.0334, valid/input_seq_len/accuracy-256=0.0179, valid/input_seq_len/accuracy-512=0.0063]\n",
            "Train Epoch 14/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=5.36]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 296.79it/s, valid/loss=4.58, valid/accuracy=0.124, valid/input_seq_len/accuracy-64=0.21, valid/input_seq_len/accuracy-128=0.0689, valid/input_seq_len/accuracy-256=0.0329, valid/input_seq_len/accuracy-512=0.0143]\n",
            "Train Epoch 15/20: 100% 785/785 [00:37<00:00, 21.07it/s, loss=5]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 299.32it/s, valid/loss=3.64, valid/accuracy=0.211, valid/input_seq_len/accuracy-64=0.364, valid/input_seq_len/accuracy-128=0.103, valid/input_seq_len/accuracy-256=0.0492, valid/input_seq_len/accuracy-512=0.021]\n",
            "Train Epoch 16/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=4.97]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 301.82it/s, valid/loss=3.49, valid/accuracy=0.237, valid/input_seq_len/accuracy-64=0.412, valid/input_seq_len/accuracy-128=0.114, valid/input_seq_len/accuracy-256=0.0517, valid/input_seq_len/accuracy-512=0.0214]\n",
            "Train Epoch 17/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=4.95]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 298.54it/s, valid/loss=3.42, valid/accuracy=0.25, valid/input_seq_len/accuracy-64=0.436, valid/input_seq_len/accuracy-128=0.117, valid/input_seq_len/accuracy-256=0.0531, valid/input_seq_len/accuracy-512=0.0217]\n",
            "Train Epoch 18/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=4.93]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 299.62it/s, valid/loss=3.36, valid/accuracy=0.26, valid/input_seq_len/accuracy-64=0.454, valid/input_seq_len/accuracy-128=0.119, valid/input_seq_len/accuracy-256=0.0542, valid/input_seq_len/accuracy-512=0.0221]\n",
            "Train Epoch 19/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=4.93]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 282.97it/s, valid/loss=3.33, valid/accuracy=0.267, valid/input_seq_len/accuracy-64=0.469, valid/input_seq_len/accuracy-128=0.12, valid/input_seq_len/accuracy-256=0.0534, valid/input_seq_len/accuracy-512=0.0222]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▁▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ██▇▅▆▇▇▃▆▃▅▇▇▇▅▇▇▇▇▃▅▇▇▅▇▆▇▇▃▃▆▆▇▆▁▄▅▆▆▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ██▅▆▄███▄▇▄▅▃▅▇▆▅▇▇▃▃▇▇█▃▆▇▃▆▆▄▁▁▄▆▇▇▁▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▂▁▂▂▂▃▂▂▃▃▃▃▃▄▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▂▂▂▂▂▂▁▂▂▂▂▂▄▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▅▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▂▂▂▁▂▂▂▁▂▂▂▂▂▅█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▂▁▂▂▂▃▂▂▃▃▃▃▃▄▆▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▇▅█▅▅▅▄▆▅▄▄▄▄▄▃▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 364544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 32768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 4.92758\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 4.92758\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.26684\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.11978\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.05344\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.02217\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.46854\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 3.32501\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/qu3gihna\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_051133-qu3gihna/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_052427-o6u4f5x4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/o6u4f5x4\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:37<00:00, 21.05it/s, loss=5.11]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 300.29it/s, valid/loss=6.43, valid/accuracy=0.0517, valid/input_seq_len/accuracy-64=0.04, valid/input_seq_len/accuracy-128=0.117, valid/input_seq_len/accuracy-256=0.0548, valid/input_seq_len/accuracy-512=0.019]\n",
            "Train Epoch 1/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=3.33]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 294.54it/s, valid/loss=1.91, valid/accuracy=0.611, valid/input_seq_len/accuracy-64=0.911, valid/input_seq_len/accuracy-128=0.584, valid/input_seq_len/accuracy-256=0.261, valid/input_seq_len/accuracy-512=0.0901]\n",
            "Train Epoch 2/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=2.78]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 297.72it/s, valid/loss=1.57, valid/accuracy=0.682, valid/input_seq_len/accuracy-64=0.956, valid/input_seq_len/accuracy-128=0.725, valid/input_seq_len/accuracy-256=0.367, valid/input_seq_len/accuracy-512=0.131]\n",
            "Train Epoch 3/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=2.26]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 300.50it/s, valid/loss=1.31, valid/accuracy=0.729, valid/input_seq_len/accuracy-64=0.972, valid/input_seq_len/accuracy-128=0.816, valid/input_seq_len/accuracy-256=0.463, valid/input_seq_len/accuracy-512=0.175]\n",
            "Train Epoch 4/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=1.84]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 258.08it/s, valid/loss=1.1, valid/accuracy=0.767, valid/input_seq_len/accuracy-64=0.981, valid/input_seq_len/accuracy-128=0.879, valid/input_seq_len/accuracy-256=0.552, valid/input_seq_len/accuracy-512=0.227]\n",
            "Train Epoch 5/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=1.64]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 222.99it/s, valid/loss=1.05, valid/accuracy=0.776, valid/input_seq_len/accuracy-64=0.982, valid/input_seq_len/accuracy-128=0.893, valid/input_seq_len/accuracy-256=0.579, valid/input_seq_len/accuracy-512=0.241]\n",
            "Train Epoch 6/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=1.6]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 226.71it/s, valid/loss=1.04, valid/accuracy=0.779, valid/input_seq_len/accuracy-64=0.983, valid/input_seq_len/accuracy-128=0.896, valid/input_seq_len/accuracy-256=0.587, valid/input_seq_len/accuracy-512=0.243]\n",
            "Train Epoch 7/20: 100% 785/785 [00:37<00:00, 21.16it/s, loss=1.44]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 234.77it/s, valid/loss=1.01, valid/accuracy=0.784, valid/input_seq_len/accuracy-64=0.983, valid/input_seq_len/accuracy-128=0.905, valid/input_seq_len/accuracy-256=0.599, valid/input_seq_len/accuracy-512=0.251]\n",
            "Train Epoch 8/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=1.33]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 240.26it/s, valid/loss=1.01, valid/accuracy=0.786, valid/input_seq_len/accuracy-64=0.982, valid/input_seq_len/accuracy-128=0.904, valid/input_seq_len/accuracy-256=0.61, valid/input_seq_len/accuracy-512=0.257]\n",
            "Train Epoch 9/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=1.24]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 233.99it/s, valid/loss=0.978, valid/accuracy=0.793, valid/input_seq_len/accuracy-64=0.983, valid/input_seq_len/accuracy-128=0.915, valid/input_seq_len/accuracy-256=0.631, valid/input_seq_len/accuracy-512=0.264]\n",
            "Train Epoch 10/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=1.02]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 256.25it/s, valid/loss=0.89, valid/accuracy=0.809, valid/input_seq_len/accuracy-64=0.984, valid/input_seq_len/accuracy-128=0.931, valid/input_seq_len/accuracy-256=0.67, valid/input_seq_len/accuracy-512=0.299]\n",
            "Train Epoch 11/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=0.847]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 288.35it/s, valid/loss=0.807, valid/accuracy=0.825, valid/input_seq_len/accuracy-64=0.986, valid/input_seq_len/accuracy-128=0.947, valid/input_seq_len/accuracy-256=0.711, valid/input_seq_len/accuracy-512=0.331]\n",
            "Train Epoch 12/20: 100% 785/785 [00:37<00:00, 21.15it/s, loss=0.695]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 301.99it/s, valid/loss=0.745, valid/accuracy=0.837, valid/input_seq_len/accuracy-64=0.989, valid/input_seq_len/accuracy-128=0.956, valid/input_seq_len/accuracy-256=0.741, valid/input_seq_len/accuracy-512=0.356]\n",
            "Train Epoch 13/20: 100% 785/785 [00:37<00:00, 21.15it/s, loss=0.619]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 300.20it/s, valid/loss=0.723, valid/accuracy=0.842, valid/input_seq_len/accuracy-64=0.989, valid/input_seq_len/accuracy-128=0.961, valid/input_seq_len/accuracy-256=0.757, valid/input_seq_len/accuracy-512=0.368]\n",
            "Train Epoch 14/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=0.525]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 295.56it/s, valid/loss=0.695, valid/accuracy=0.849, valid/input_seq_len/accuracy-64=0.991, valid/input_seq_len/accuracy-128=0.967, valid/input_seq_len/accuracy-256=0.77, valid/input_seq_len/accuracy-512=0.383]\n",
            "Train Epoch 15/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=0.437]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 291.19it/s, valid/loss=0.656, valid/accuracy=0.857, valid/input_seq_len/accuracy-64=0.991, valid/input_seq_len/accuracy-128=0.972, valid/input_seq_len/accuracy-256=0.793, valid/input_seq_len/accuracy-512=0.405]\n",
            "Train Epoch 16/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=0.37]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 294.31it/s, valid/loss=0.632, valid/accuracy=0.862, valid/input_seq_len/accuracy-64=0.992, valid/input_seq_len/accuracy-128=0.973, valid/input_seq_len/accuracy-256=0.803, valid/input_seq_len/accuracy-512=0.416]\n",
            "Train Epoch 17/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=0.313]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 296.63it/s, valid/loss=0.612, valid/accuracy=0.865, valid/input_seq_len/accuracy-64=0.994, valid/input_seq_len/accuracy-128=0.975, valid/input_seq_len/accuracy-256=0.811, valid/input_seq_len/accuracy-512=0.424]\n",
            "Train Epoch 18/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=0.279]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 297.67it/s, valid/loss=0.594, valid/accuracy=0.868, valid/input_seq_len/accuracy-64=0.996, valid/input_seq_len/accuracy-128=0.976, valid/input_seq_len/accuracy-256=0.815, valid/input_seq_len/accuracy-512=0.429]\n",
            "Train Epoch 19/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=0.261]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 300.34it/s, valid/loss=0.588, valid/accuracy=0.87, valid/input_seq_len/accuracy-64=0.998, valid/input_seq_len/accuracy-128=0.977, valid/input_seq_len/accuracy-256=0.817, valid/input_seq_len/accuracy-512=0.43]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▂▂▂▂▂▂▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █▃▂▂▁▅▅▁▁▁▁▂▃▁▁▁▁▂▁▁▁▃▃▁▁▁▁▁▂▂▁▂▁▁▁▂▁▁▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ██▇▆▆▆▆▆▂▃▁▁▂▂▄▁▁▁▁▂▁▃▃▃▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▆▆▇▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▅▆▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▃▄▅▆▆▆▆▆▆▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▂▃▄▅▅▅▅▅▅▆▆▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▇██████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss █▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 364544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 32768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 0.26083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 0.26083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.86956\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.97669\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.8173\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.42967\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.9979\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 0.5883\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/o6u4f5x4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_052427-o6u4f5x4/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_053721-i1uhphb2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/i1uhphb2\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.03162277660168379\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [00:37<00:00, 21.05it/s, loss=6.26]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 295.71it/s, valid/loss=6.25, valid/accuracy=0.00157, valid/input_seq_len/accuracy-64=0.000958, valid/input_seq_len/accuracy-128=0.00241, valid/input_seq_len/accuracy-256=0.00225, valid/input_seq_len/accuracy-512=0.00191]\n",
            "Train Epoch 1/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=6.26]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 296.51it/s, valid/loss=6.25, valid/accuracy=0.00172, valid/input_seq_len/accuracy-64=0.0014, valid/input_seq_len/accuracy-128=0.00216, valid/input_seq_len/accuracy-256=0.00191, valid/input_seq_len/accuracy-512=0.00207]\n",
            "Train Epoch 2/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=6.26]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 297.24it/s, valid/loss=6.25, valid/accuracy=0.0016, valid/input_seq_len/accuracy-64=0.000979, valid/input_seq_len/accuracy-128=0.00247, valid/input_seq_len/accuracy-256=0.00213, valid/input_seq_len/accuracy-512=0.00205]\n",
            "Train Epoch 3/20: 100% 785/785 [00:37<00:00, 21.06it/s, loss=6.26]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 297.89it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 4/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=6.26]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 296.94it/s, valid/loss=6.25, valid/accuracy=0.00215, valid/input_seq_len/accuracy-64=0.00217, valid/input_seq_len/accuracy-128=0.00253, valid/input_seq_len/accuracy-256=0.00198, valid/input_seq_len/accuracy-512=0.00187]\n",
            "Train Epoch 5/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=6.25]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 231.62it/s, valid/loss=6.25, valid/accuracy=0.00167, valid/input_seq_len/accuracy-64=0.00106, valid/input_seq_len/accuracy-128=0.00244, valid/input_seq_len/accuracy-256=0.00223, valid/input_seq_len/accuracy-512=0.00217]\n",
            "Train Epoch 6/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=6.25]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 221.79it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 7/20: 100% 785/785 [00:37<00:00, 21.15it/s, loss=6.25]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 234.80it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 8/20: 100% 785/785 [00:37<00:00, 21.13it/s, loss=6.25]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 233.22it/s, valid/loss=6.25, valid/accuracy=0.00177, valid/input_seq_len/accuracy-64=0.00146, valid/input_seq_len/accuracy-128=0.00228, valid/input_seq_len/accuracy-256=0.00192, valid/input_seq_len/accuracy-512=0.00202]\n",
            "Train Epoch 9/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=6.25]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 235.73it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 10/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=6.25]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 252.64it/s, valid/loss=6.24, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 11/20: 100% 785/785 [00:37<00:00, 21.09it/s, loss=6.25]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 281.37it/s, valid/loss=6.24, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 12/20: 100% 785/785 [00:37<00:00, 21.08it/s, loss=6.24]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 298.29it/s, valid/loss=6.24, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 13/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=6.24]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 299.64it/s, valid/loss=6.24, valid/accuracy=0.00226, valid/input_seq_len/accuracy-64=0.00248, valid/input_seq_len/accuracy-128=0.00191, valid/input_seq_len/accuracy-256=0.00205, valid/input_seq_len/accuracy-512=0.00216]\n",
            "Train Epoch 14/20: 100% 785/785 [00:37<00:00, 21.12it/s, loss=6.24]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 303.74it/s, valid/loss=6.24, valid/accuracy=0.00224, valid/input_seq_len/accuracy-64=0.00246, valid/input_seq_len/accuracy-128=0.00191, valid/input_seq_len/accuracy-256=0.002, valid/input_seq_len/accuracy-512=0.00214]\n",
            "Train Epoch 15/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=6.23]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 297.60it/s, valid/loss=6.27, valid/accuracy=0.00218, valid/input_seq_len/accuracy-64=0.00204, valid/input_seq_len/accuracy-128=0.002, valid/input_seq_len/accuracy-256=0.00264, valid/input_seq_len/accuracy-512=0.00232]\n",
            "Train Epoch 16/20: 100% 785/785 [00:37<00:00, 21.16it/s, loss=6.18]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 302.27it/s, valid/loss=6.75, valid/accuracy=0.00291, valid/input_seq_len/accuracy-64=0.00229, valid/input_seq_len/accuracy-128=0.00369, valid/input_seq_len/accuracy-256=0.00381, valid/input_seq_len/accuracy-512=0.0031]\n",
            "Train Epoch 17/20: 100% 785/785 [00:37<00:00, 21.10it/s, loss=6.1]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 302.23it/s, valid/loss=6.4, valid/accuracy=0.0114, valid/input_seq_len/accuracy-64=0.0125, valid/input_seq_len/accuracy-128=0.0158, valid/input_seq_len/accuracy-256=0.00962, valid/input_seq_len/accuracy-512=0.0053]\n",
            "Train Epoch 18/20: 100% 785/785 [00:37<00:00, 21.14it/s, loss=6.05]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 301.57it/s, valid/loss=6.05, valid/accuracy=0.0433, valid/input_seq_len/accuracy-64=0.0701, valid/input_seq_len/accuracy-128=0.0293, valid/input_seq_len/accuracy-256=0.0137, valid/input_seq_len/accuracy-512=0.00634]\n",
            "Train Epoch 19/20: 100% 785/785 [00:37<00:00, 21.11it/s, loss=6.05]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 302.44it/s, valid/loss=5.77, valid/accuracy=0.0739, valid/input_seq_len/accuracy-64=0.131, valid/input_seq_len/accuracy-128=0.0307, valid/input_seq_len/accuracy-256=0.0131, valid/input_seq_len/accuracy-512=0.00688]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █████████████████████████▇██▇▇▇▇▆▆▅▆▆▆▁▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ███████████████████████████▇██▆▆▇▇▇▄▆▁▇▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅█▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 364544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 32768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 6.04652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 6.04652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.07387\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.03075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.01306\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.13083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 5.76812\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/i1uhphb2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_053721-i1uhphb2/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_055015-9r86sinx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/9r86sinx\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.001\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [01:24<00:00,  9.34it/s, loss=5.58]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:02<00:00, 177.64it/s, valid/loss=6.09, valid/accuracy=0.0432, valid/input_seq_len/accuracy-64=0.0683, valid/input_seq_len/accuracy-128=0.0262, valid/input_seq_len/accuracy-256=0.0203, valid/input_seq_len/accuracy-512=0.00749]\n",
            "Train Epoch 1/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=5.51]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 213.16it/s, valid/loss=6.28, valid/accuracy=0.0472, valid/input_seq_len/accuracy-64=0.0766, valid/input_seq_len/accuracy-128=0.0253, valid/input_seq_len/accuracy-256=0.0203, valid/input_seq_len/accuracy-512=0.00776]\n",
            "Train Epoch 2/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=5.49]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 212.87it/s, valid/loss=6.2, valid/accuracy=0.0478, valid/input_seq_len/accuracy-64=0.0774, valid/input_seq_len/accuracy-128=0.0262, valid/input_seq_len/accuracy-256=0.021, valid/input_seq_len/accuracy-512=0.00771]\n",
            "Train Epoch 3/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.5]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 210.48it/s, valid/loss=6.61, valid/accuracy=0.0286, valid/input_seq_len/accuracy-64=0.0401, valid/input_seq_len/accuracy-128=0.024, valid/input_seq_len/accuracy-256=0.0195, valid/input_seq_len/accuracy-512=0.00813]\n",
            "Train Epoch 4/20: 100% 785/785 [01:19<00:00,  9.86it/s, loss=5.48]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:02<00:00, 184.94it/s, valid/loss=6.19, valid/accuracy=0.0355, valid/input_seq_len/accuracy-64=0.0503, valid/input_seq_len/accuracy-128=0.0357, valid/input_seq_len/accuracy-256=0.0193, valid/input_seq_len/accuracy-512=0.00732]\n",
            "Train Epoch 5/20: 100% 785/785 [01:19<00:00,  9.86it/s, loss=5.48]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 210.07it/s, valid/loss=6.15, valid/accuracy=0.0348, valid/input_seq_len/accuracy-64=0.0488, valid/input_seq_len/accuracy-128=0.0359, valid/input_seq_len/accuracy-256=0.019, valid/input_seq_len/accuracy-512=0.00787]\n",
            "Train Epoch 6/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.47]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 213.19it/s, valid/loss=5.83, valid/accuracy=0.047, valid/input_seq_len/accuracy-64=0.0726, valid/input_seq_len/accuracy-128=0.0365, valid/input_seq_len/accuracy-256=0.0197, valid/input_seq_len/accuracy-512=0.00784]\n",
            "Train Epoch 7/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.44]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 210.69it/s, valid/loss=4.83, valid/accuracy=0.0814, valid/input_seq_len/accuracy-64=0.14, valid/input_seq_len/accuracy-128=0.0388, valid/input_seq_len/accuracy-256=0.02, valid/input_seq_len/accuracy-512=0.008]\n",
            "Train Epoch 8/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.42]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 206.68it/s, valid/loss=4.71, valid/accuracy=0.0808, valid/input_seq_len/accuracy-64=0.139, valid/input_seq_len/accuracy-128=0.0391, valid/input_seq_len/accuracy-256=0.0205, valid/input_seq_len/accuracy-512=0.00759]\n",
            "Train Epoch 9/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.4]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:02<00:00, 179.85it/s, valid/loss=4.62, valid/accuracy=0.0807, valid/input_seq_len/accuracy-64=0.139, valid/input_seq_len/accuracy-128=0.0393, valid/input_seq_len/accuracy-256=0.0204, valid/input_seq_len/accuracy-512=0.00803]\n",
            "Train Epoch 10/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=5.39]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 209.39it/s, valid/loss=4.69, valid/accuracy=0.085, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.04, valid/input_seq_len/accuracy-256=0.021, valid/input_seq_len/accuracy-512=0.0082]\n",
            "Train Epoch 11/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.36]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 213.77it/s, valid/loss=4.69, valid/accuracy=0.09, valid/input_seq_len/accuracy-64=0.156, valid/input_seq_len/accuracy-128=0.0409, valid/input_seq_len/accuracy-256=0.022, valid/input_seq_len/accuracy-512=0.00818]\n",
            "Train Epoch 12/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.32]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 210.46it/s, valid/loss=4.57, valid/accuracy=0.108, valid/input_seq_len/accuracy-64=0.189, valid/input_seq_len/accuracy-128=0.0505, valid/input_seq_len/accuracy-256=0.0242, valid/input_seq_len/accuracy-512=0.00841]\n",
            "Train Epoch 13/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.29]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:02<00:00, 183.50it/s, valid/loss=4.48, valid/accuracy=0.125, valid/input_seq_len/accuracy-64=0.22, valid/input_seq_len/accuracy-128=0.0576, valid/input_seq_len/accuracy-256=0.0257, valid/input_seq_len/accuracy-512=0.00878]\n",
            "Train Epoch 14/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.28]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 202.99it/s, valid/loss=4.48, valid/accuracy=0.135, valid/input_seq_len/accuracy-64=0.239, valid/input_seq_len/accuracy-128=0.0595, valid/input_seq_len/accuracy-256=0.027, valid/input_seq_len/accuracy-512=0.00909]\n",
            "Train Epoch 15/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=5.26]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 211.42it/s, valid/loss=4.44, valid/accuracy=0.145, valid/input_seq_len/accuracy-64=0.259, valid/input_seq_len/accuracy-128=0.0594, valid/input_seq_len/accuracy-256=0.0275, valid/input_seq_len/accuracy-512=0.00916]\n",
            "Train Epoch 16/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=4.84]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 210.22it/s, valid/loss=4.09, valid/accuracy=0.184, valid/input_seq_len/accuracy-64=0.315, valid/input_seq_len/accuracy-128=0.0975, valid/input_seq_len/accuracy-256=0.0457, valid/input_seq_len/accuracy-512=0.0164]\n",
            "Train Epoch 17/20: 100% 785/785 [01:19<00:00,  9.87it/s, loss=4.78]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 210.97it/s, valid/loss=3.62, valid/accuracy=0.224, valid/input_seq_len/accuracy-64=0.388, valid/input_seq_len/accuracy-128=0.112, valid/input_seq_len/accuracy-256=0.05, valid/input_seq_len/accuracy-512=0.0178]\n",
            "Train Epoch 18/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=4.77]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:02<00:00, 182.91it/s, valid/loss=3.46, valid/accuracy=0.245, valid/input_seq_len/accuracy-64=0.426, valid/input_seq_len/accuracy-128=0.118, valid/input_seq_len/accuracy-256=0.051, valid/input_seq_len/accuracy-512=0.0186]\n",
            "Train Epoch 19/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=4.78]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 212.70it/s, valid/loss=3.38, valid/accuracy=0.259, valid/input_seq_len/accuracy-64=0.454, valid/input_seq_len/accuracy-128=0.12, valid/input_seq_len/accuracy-256=0.0509, valid/input_seq_len/accuracy-512=0.0186]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss █▆▆▆▃▆▃▃▄▅▇▄▂▂▂▆▃▂▄▇▅▄▆▇▆▃▁▃▆▅▁▃▇▄▆▁▄▄▅▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss █▇▇▄▄▆▇▄▆▇▆▆▃▄▇▇▇▃▄▆▇▂▆▂▂▅▆▅▅▇▆▆▆▇▂▁▁▂▄▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▂▂▁▁▁▂▃▃▃▃▃▃▄▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▁▂▁▁▁▁▁▁▂▂▂▂▂▂▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▂▂▁▁▁▂▃▃▃▃▃▄▄▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▇▇▇█▇▇▆▄▄▄▄▄▄▃▃▃▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 1138688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 65536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 4.77788\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 4.77788\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.25862\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.11984\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.05086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.01863\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.45413\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 3.38122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/9r86sinx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_055015-9r86sinx/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_061728-jp170tii\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-03\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/jp170tii\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0031622776601683794\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-03'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [01:19<00:00,  9.87it/s, loss=5.65]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 209.04it/s, valid/loss=5.9, valid/accuracy=0.0612, valid/input_seq_len/accuracy-64=0.1, valid/input_seq_len/accuracy-128=0.0385, valid/input_seq_len/accuracy-256=0.0195, valid/input_seq_len/accuracy-512=0.00882]\n",
            "Train Epoch 1/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.54]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 193.44it/s, valid/loss=6.09, valid/accuracy=0.0652, valid/input_seq_len/accuracy-64=0.108, valid/input_seq_len/accuracy-128=0.0379, valid/input_seq_len/accuracy-256=0.022, valid/input_seq_len/accuracy-512=0.00852]\n",
            "Train Epoch 2/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=5.52]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 189.59it/s, valid/loss=7.34, valid/accuracy=0.035, valid/input_seq_len/accuracy-64=0.0483, valid/input_seq_len/accuracy-128=0.0349, valid/input_seq_len/accuracy-256=0.0225, valid/input_seq_len/accuracy-512=0.00797]\n",
            "Train Epoch 3/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=5.53]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 212.76it/s, valid/loss=5.87, valid/accuracy=0.0608, valid/input_seq_len/accuracy-64=0.0985, valid/input_seq_len/accuracy-128=0.0374, valid/input_seq_len/accuracy-256=0.0223, valid/input_seq_len/accuracy-512=0.00941]\n",
            "Train Epoch 4/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.51]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 213.10it/s, valid/loss=4.96, valid/accuracy=0.0901, valid/input_seq_len/accuracy-64=0.156, valid/input_seq_len/accuracy-128=0.0408, valid/input_seq_len/accuracy-256=0.0229, valid/input_seq_len/accuracy-512=0.00978]\n",
            "Train Epoch 5/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.5]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 213.35it/s, valid/loss=7.32, valid/accuracy=0.029, valid/input_seq_len/accuracy-64=0.0389, valid/input_seq_len/accuracy-128=0.0271, valid/input_seq_len/accuracy-256=0.0226, valid/input_seq_len/accuracy-512=0.0076]\n",
            "Train Epoch 6/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.48]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 190.11it/s, valid/loss=5.31, valid/accuracy=0.0769, valid/input_seq_len/accuracy-64=0.13, valid/input_seq_len/accuracy-128=0.0389, valid/input_seq_len/accuracy-256=0.0241, valid/input_seq_len/accuracy-512=0.00886]\n",
            "Train Epoch 7/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.46]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 208.38it/s, valid/loss=7.19, valid/accuracy=0.0372, valid/input_seq_len/accuracy-64=0.0553, valid/input_seq_len/accuracy-128=0.0266, valid/input_seq_len/accuracy-256=0.0226, valid/input_seq_len/accuracy-512=0.0082]\n",
            "Train Epoch 8/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=5.46]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 212.45it/s, valid/loss=5.44, valid/accuracy=0.063, valid/input_seq_len/accuracy-64=0.104, valid/input_seq_len/accuracy-128=0.0366, valid/input_seq_len/accuracy-256=0.0235, valid/input_seq_len/accuracy-512=0.00652]\n",
            "Train Epoch 9/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=5.46]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 209.20it/s, valid/loss=4.43, valid/accuracy=0.085, valid/input_seq_len/accuracy-64=0.147, valid/input_seq_len/accuracy-128=0.0394, valid/input_seq_len/accuracy-256=0.0232, valid/input_seq_len/accuracy-512=0.00733]\n",
            "Train Epoch 10/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.44]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 212.65it/s, valid/loss=4.38, valid/accuracy=0.0877, valid/input_seq_len/accuracy-64=0.153, valid/input_seq_len/accuracy-128=0.0388, valid/input_seq_len/accuracy-256=0.0229, valid/input_seq_len/accuracy-512=0.00645]\n",
            "Train Epoch 11/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=5.43]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:02<00:00, 185.61it/s, valid/loss=4.44, valid/accuracy=0.09, valid/input_seq_len/accuracy-64=0.158, valid/input_seq_len/accuracy-128=0.0367, valid/input_seq_len/accuracy-256=0.0232, valid/input_seq_len/accuracy-512=0.0073]\n",
            "Train Epoch 12/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.42]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 214.05it/s, valid/loss=4.54, valid/accuracy=0.0885, valid/input_seq_len/accuracy-64=0.155, valid/input_seq_len/accuracy-128=0.0346, valid/input_seq_len/accuracy-256=0.023, valid/input_seq_len/accuracy-512=0.00729]\n",
            "Train Epoch 13/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.41]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 213.81it/s, valid/loss=5.85, valid/accuracy=0.0614, valid/input_seq_len/accuracy-64=0.102, valid/input_seq_len/accuracy-128=0.0329, valid/input_seq_len/accuracy-256=0.0229, valid/input_seq_len/accuracy-512=0.00745]\n",
            "Train Epoch 14/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.41]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 211.99it/s, valid/loss=4.35, valid/accuracy=0.0863, valid/input_seq_len/accuracy-64=0.149, valid/input_seq_len/accuracy-128=0.0389, valid/input_seq_len/accuracy-256=0.0235, valid/input_seq_len/accuracy-512=0.00727]\n",
            "Train Epoch 15/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.4]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 209.67it/s, valid/loss=4.35, valid/accuracy=0.0864, valid/input_seq_len/accuracy-64=0.149, valid/input_seq_len/accuracy-128=0.0395, valid/input_seq_len/accuracy-256=0.0232, valid/input_seq_len/accuracy-512=0.00737]\n",
            "Train Epoch 16/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=5.39]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:02<00:00, 181.32it/s, valid/loss=4.35, valid/accuracy=0.0873, valid/input_seq_len/accuracy-64=0.151, valid/input_seq_len/accuracy-128=0.0395, valid/input_seq_len/accuracy-256=0.0231, valid/input_seq_len/accuracy-512=0.00755]\n",
            "Train Epoch 17/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.39]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 212.49it/s, valid/loss=4.34, valid/accuracy=0.0874, valid/input_seq_len/accuracy-64=0.151, valid/input_seq_len/accuracy-128=0.0396, valid/input_seq_len/accuracy-256=0.0225, valid/input_seq_len/accuracy-512=0.00787]\n",
            "Train Epoch 18/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=5.39]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 212.00it/s, valid/loss=4.33, valid/accuracy=0.0869, valid/input_seq_len/accuracy-64=0.15, valid/input_seq_len/accuracy-128=0.0399, valid/input_seq_len/accuracy-256=0.0222, valid/input_seq_len/accuracy-512=0.00777]\n",
            "Train Epoch 19/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=5.39]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 210.17it/s, valid/loss=4.3, valid/accuracy=0.0863, valid/input_seq_len/accuracy-64=0.149, valid/input_seq_len/accuracy-128=0.0394, valid/input_seq_len/accuracy-256=0.022, valid/input_seq_len/accuracy-512=0.00763]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ▇█▆▇█▇██▆▆▇▄█▆▄▄▅▂▃▅▇█▃▅▆█▃▃▇█▃▇▁▅█▇█▃▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ███▃▃█▆▆▆▆▂▂▅▇▇▅▂▄▅█▇██▁▃▃▁▅▇▁██▁▇▇▃▇▃█▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▅▅▂▅█▁▆▂▅▇███▅██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▇▇▅▆█▁▇▁▆▇▇▆▅▄▇▇▇▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▅▆▅▆▆█▆▇▇▆▇▆▆▇▇▇▆▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▆▅▄▇█▃▆▅▁▃▁▃▃▃▃▃▃▄▄▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▅▅▂▅█▁▆▂▅▇███▅██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▅▅█▅▃█▃█▄▁▁▁▂▅▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 1138688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 65536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 5.39315\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 5.39315\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.08625\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.03941\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.02198\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.00763\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.1495\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 4.30016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-03\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/jp170tii\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_061728-jp170tii/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_064433-4akzzb0x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr1.0e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/4akzzb0x\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr1.0e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=6.24]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 193.22it/s, valid/loss=6.25, valid/accuracy=0.00219, valid/input_seq_len/accuracy-64=0.00179, valid/input_seq_len/accuracy-128=0.00297, valid/input_seq_len/accuracy-256=0.00273, valid/input_seq_len/accuracy-512=0.00204]\n",
            "Train Epoch 1/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=6.04]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 213.99it/s, valid/loss=7.37, valid/accuracy=0.00624, valid/input_seq_len/accuracy-64=0.00454, valid/input_seq_len/accuracy-128=0.0113, valid/input_seq_len/accuracy-256=0.00805, valid/input_seq_len/accuracy-512=0.00441]\n",
            "Train Epoch 2/20: 100% 785/785 [01:19<00:00,  9.87it/s, loss=1.23]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 211.58it/s, valid/loss=1.16, valid/accuracy=0.759, valid/input_seq_len/accuracy-64=0.883, valid/input_seq_len/accuracy-128=0.892, valid/input_seq_len/accuracy-256=0.688, valid/input_seq_len/accuracy-512=0.326]\n",
            "Train Epoch 3/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=0.649]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 211.46it/s, valid/loss=0.539, valid/accuracy=0.877, valid/input_seq_len/accuracy-64=0.998, valid/input_seq_len/accuracy-128=0.971, valid/input_seq_len/accuracy-256=0.826, valid/input_seq_len/accuracy-512=0.47]\n",
            "Train Epoch 4/20: 100% 785/785 [01:19<00:00,  9.89it/s, loss=0.347]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:02<00:00, 186.17it/s, valid/loss=0.391, valid/accuracy=0.908, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.987, valid/input_seq_len/accuracy-256=0.893, valid/input_seq_len/accuracy-512=0.569]\n",
            "Train Epoch 5/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=0.274]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 213.07it/s, valid/loss=0.351, valid/accuracy=0.917, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.99, valid/input_seq_len/accuracy-256=0.913, valid/input_seq_len/accuracy-512=0.602]\n",
            "Train Epoch 6/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=0.232]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 212.47it/s, valid/loss=0.304, valid/accuracy=0.927, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.994, valid/input_seq_len/accuracy-256=0.93, valid/input_seq_len/accuracy-512=0.638]\n",
            "Train Epoch 7/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=0.196]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:01<00:00, 212.60it/s, valid/loss=0.274, valid/accuracy=0.934, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.995, valid/input_seq_len/accuracy-256=0.941, valid/input_seq_len/accuracy-512=0.669]\n",
            "Train Epoch 8/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=0.185]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:01<00:00, 211.67it/s, valid/loss=0.258, valid/accuracy=0.937, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.996, valid/input_seq_len/accuracy-256=0.946, valid/input_seq_len/accuracy-512=0.684]\n",
            "Train Epoch 9/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=0.135]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:02<00:00, 183.97it/s, valid/loss=0.239, valid/accuracy=0.941, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.996, valid/input_seq_len/accuracy-256=0.952, valid/input_seq_len/accuracy-512=0.702]\n",
            "Train Epoch 10/20: 100% 785/785 [01:19<00:00,  9.88it/s, loss=0.113]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 212.81it/s, valid/loss=0.226, valid/accuracy=0.945, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.997, valid/input_seq_len/accuracy-256=0.957, valid/input_seq_len/accuracy-512=0.715]\n",
            "Train Epoch 11/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=0.0872]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 210.80it/s, valid/loss=0.218, valid/accuracy=0.946, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.997, valid/input_seq_len/accuracy-256=0.96, valid/input_seq_len/accuracy-512=0.723]\n",
            "Train Epoch 12/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=0.0613]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 215.10it/s, valid/loss=0.209, valid/accuracy=0.949, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.997, valid/input_seq_len/accuracy-256=0.963, valid/input_seq_len/accuracy-512=0.734]\n",
            "Train Epoch 13/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=0.0554]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 211.13it/s, valid/loss=0.194, valid/accuracy=0.952, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.998, valid/input_seq_len/accuracy-256=0.968, valid/input_seq_len/accuracy-512=0.748]\n",
            "Train Epoch 14/20: 100% 785/785 [01:19<00:00,  9.90it/s, loss=0.0324]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:02<00:00, 179.95it/s, valid/loss=0.184, valid/accuracy=0.955, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.971, valid/input_seq_len/accuracy-512=0.758]\n",
            "Train Epoch 15/20: 100% 785/785 [01:19<00:00,  9.93it/s, loss=0.0158]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 213.44it/s, valid/loss=0.172, valid/accuracy=0.957, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.975, valid/input_seq_len/accuracy-512=0.77]\n",
            "Train Epoch 16/20: 100% 785/785 [01:19<00:00,  9.93it/s, loss=0.00991]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:01<00:00, 209.73it/s, valid/loss=0.155, valid/accuracy=0.961, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.979, valid/input_seq_len/accuracy-512=0.789]\n",
            "Train Epoch 17/20: 100% 785/785 [01:18<00:00,  9.95it/s, loss=0.00569]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 215.35it/s, valid/loss=0.147, valid/accuracy=0.963, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.981, valid/input_seq_len/accuracy-512=0.797]\n",
            "Train Epoch 18/20: 100% 785/785 [01:19<00:00,  9.91it/s, loss=0.00356]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 212.75it/s, valid/loss=0.138, valid/accuracy=0.965, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.984, valid/input_seq_len/accuracy-512=0.807]\n",
            "Train Epoch 19/20: 100% 785/785 [01:18<00:00,  9.94it/s, loss=0.00294]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:02<00:00, 186.24it/s, valid/loss=0.136, valid/accuracy=0.965, valid/input_seq_len/accuracy-64=1, valid/input_seq_len/accuracy-128=0.999, valid/input_seq_len/accuracy-256=0.984, valid/input_seq_len/accuracy-512=0.81]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ████▄▃▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss ██████▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▁▇▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▇█████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▆▇▇▇██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▄▅▆▆▇▇▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▁▇█████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▇█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 1138688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 65536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 0.00294\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 0.00294\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.9655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.99941\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.98444\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.80965\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.99983\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 0.13574\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr1.0e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/4akzzb0x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_064433-4akzzb0x/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/HW_mamba/wandb/run-20241117_071137-f98njkv4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmamba-lr3.2e-02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/f98njkv4\u001b[0m\n",
            "\u001b[1;35mTrainConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "    \u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33mtrain_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m20000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mtest_configs\u001b[0m=\u001b[1m[\u001b[0m\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m64\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m,\n",
            "            \u001b[1;35mMQARConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "                \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "                \u001b[33mnum_examples\u001b[0m=\u001b[1;36m1000\u001b[0m,\n",
            "                \u001b[33minput_seq_len\u001b[0m=\u001b[1;36m512\u001b[0m,\n",
            "                \u001b[33mname\u001b[0m=\u001b[32m'multiquery_ar'\u001b[0m,\n",
            "                \u001b[33mpower_a\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
            "                \u001b[33mnum_kv_pairs\u001b[0m=\u001b[1;36m128\u001b[0m,\n",
            "                \u001b[33mrandom_non_queries\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "                \u001b[33minclude_slices\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
            "            \u001b[1m)\u001b[0m\n",
            "        \u001b[1m]\u001b[0m,\n",
            "        \u001b[33mbatch_size\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "        \u001b[33mcache_dir\u001b[0m=\u001b[32m'/var/cr05_data/sabri_data/zoology'\u001b[0m,\n",
            "        \u001b[33mforce_cache\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\n",
            "        \u001b[33msequence_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'zoology.mixers.mamba.Mamba'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'd_state'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33mstate_mixer\u001b[0m=\u001b[1;35mModuleConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.nn.Identity'\u001b[0m, \u001b[33mkwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
            "        \u001b[33md_model\u001b[0m=\u001b[1;36m256\u001b[0m,\n",
            "        \u001b[33mn_layers\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
            "        \u001b[33mmax_position_embeddings\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
            "        \u001b[33mlearnable_word_embeddings\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
            "        \u001b[33mvocab_size\u001b[0m=\u001b[1;36m1024\u001b[0m,\n",
            "        \u001b[33mresid_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33membed_dropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "        \u001b[33mdrop_path\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
            "        \u001b[33mlayer_norm_epsilon\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m,\n",
            "        \u001b[33mpad_vocab_size_multiple\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
            "        \u001b[33mblock_type\u001b[0m=\u001b[32m'MambaBlock'\u001b[0m,\n",
            "        \u001b[33mname\u001b[0m=\u001b[32m'mamba'\u001b[0m\n",
            "    \u001b[1m)\u001b[0m,\n",
            "    \u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject_name\u001b[0m=\u001b[32m'HW_mamba'\u001b[0m, \u001b[33mentity\u001b[0m=\u001b[32m'llms_argh'\u001b[0m\u001b[1m)\u001b[0m,\n",
            "    \u001b[33mmax_epochs\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
            "    \u001b[33mearly_stopping_metric\u001b[0m=\u001b[32m'valid/accuracy'\u001b[0m,\n",
            "    \u001b[33mearly_stopping_threshold\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.99\u001b[0m,\n",
            "    \u001b[33mslice_keys\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input_seq_len'\u001b[0m\u001b[1m]\u001b[0m,\n",
            "    \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.03162277660168379\u001b[0m,\n",
            "    \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m,\n",
            "    \u001b[33mseed\u001b[0m=\u001b[1;36m123\u001b[0m,\n",
            "    \u001b[33mlaunch_id\u001b[0m=\u001b[32m'default-2024-11-17-04-29-05'\u001b[0m,\n",
            "    \u001b[33msweep_id\u001b[0m=\u001b[32m'kvs-lin-attn-sweep80d5c9'\u001b[0m,\n",
            "    \u001b[33mrun_id\u001b[0m=\u001b[32m'mamba-lr3.2e-02'\u001b[0m\n",
            "\u001b[1m)\u001b[0m\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0e3c2b087d04e4b9c45569553947f891.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_589138b5b5d087c84393013d7ff2ff66.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_36ca02bf3ad524c5873c799ce8607cfc.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_0cc93e370bbc27429a46a101b91f2d8a.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_2b99a110b5646ac3782d1335122a7832.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_8f5063b0039c085cae94dace3c11a874.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_6d12d65be780e95da40df6b07dfe2c5d.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_609f1fdef945bd12f139cb5da134f342.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_d57e2ef5fd724ed9ebdecccf11947a58.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_551691eae934ca00039a812bfc3dc78c.pt...\n",
            "Loading data from on-disk cache at /var/cr05_data/sabri_data/zoology/data_97d83259030fa2494483f0a4279e2aa7.pt...\n",
            "Train Epoch 0/20: 100% 785/785 [01:19<00:00,  9.92it/s, loss=6.25]\n",
            "Valid Epoch 0/20: 100% 378/378 [00:01<00:00, 212.90it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 1/20: 100% 785/785 [01:18<00:00, 10.05it/s, loss=6.25]\n",
            "Valid Epoch 1/20: 100% 378/378 [00:01<00:00, 212.95it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 2/20: 100% 785/785 [01:17<00:00, 10.17it/s, loss=6.25]\n",
            "Valid Epoch 2/20: 100% 378/378 [00:01<00:00, 210.50it/s, valid/loss=6.25, valid/accuracy=0.00157, valid/input_seq_len/accuracy-64=0.00115, valid/input_seq_len/accuracy-128=0.00191, valid/input_seq_len/accuracy-256=0.00208, valid/input_seq_len/accuracy-512=0.00198]\n",
            "Train Epoch 3/20: 100% 785/785 [01:16<00:00, 10.31it/s, loss=6.25]\n",
            "Valid Epoch 3/20: 100% 378/378 [00:01<00:00, 212.91it/s, valid/loss=6.25, valid/accuracy=0.00164, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00241, valid/input_seq_len/accuracy-256=0.00228, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 4/20: 100% 785/785 [01:16<00:00, 10.31it/s, loss=6.25]\n",
            "Valid Epoch 4/20: 100% 378/378 [00:01<00:00, 214.95it/s, valid/loss=6.25, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 5/20: 100% 785/785 [01:15<00:00, 10.37it/s, loss=6.25]\n",
            "Valid Epoch 5/20: 100% 378/378 [00:01<00:00, 214.85it/s, valid/loss=6.24, valid/accuracy=0.0017, valid/input_seq_len/accuracy-64=0.00125, valid/input_seq_len/accuracy-128=0.00219, valid/input_seq_len/accuracy-256=0.00237, valid/input_seq_len/accuracy-512=0.0019]\n",
            "Train Epoch 6/20: 100% 785/785 [01:15<00:00, 10.39it/s, loss=6.25]\n",
            "Valid Epoch 6/20: 100% 378/378 [00:01<00:00, 213.55it/s, valid/loss=6.24, valid/accuracy=0.0016, valid/input_seq_len/accuracy-64=0.00102, valid/input_seq_len/accuracy-128=0.00234, valid/input_seq_len/accuracy-256=0.00223, valid/input_seq_len/accuracy-512=0.00197]\n",
            "Train Epoch 7/20: 100% 785/785 [01:15<00:00, 10.38it/s, loss=6.25]\n",
            "Valid Epoch 7/20: 100% 378/378 [00:02<00:00, 184.88it/s, valid/loss=6.24, valid/accuracy=0.00164, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00247, valid/input_seq_len/accuracy-256=0.00222, valid/input_seq_len/accuracy-512=0.00202]\n",
            "Train Epoch 8/20: 100% 785/785 [01:15<00:00, 10.44it/s, loss=6.24]\n",
            "Valid Epoch 8/20: 100% 378/378 [00:02<00:00, 187.31it/s, valid/loss=6.24, valid/accuracy=0.00163, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00237, valid/input_seq_len/accuracy-256=0.00227, valid/input_seq_len/accuracy-512=0.002]\n",
            "Train Epoch 9/20: 100% 785/785 [01:14<00:00, 10.47it/s, loss=6.24]\n",
            "Valid Epoch 9/20: 100% 378/378 [00:01<00:00, 202.18it/s, valid/loss=6.24, valid/accuracy=0.00162, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00234, valid/input_seq_len/accuracy-256=0.00225, valid/input_seq_len/accuracy-512=0.00199]\n",
            "Train Epoch 10/20: 100% 785/785 [01:14<00:00, 10.50it/s, loss=6.24]\n",
            "Valid Epoch 10/20: 100% 378/378 [00:01<00:00, 214.64it/s, valid/loss=6.24, valid/accuracy=0.00161, valid/input_seq_len/accuracy-64=0.00104, valid/input_seq_len/accuracy-128=0.00231, valid/input_seq_len/accuracy-256=0.00213, valid/input_seq_len/accuracy-512=0.00208]\n",
            "Train Epoch 11/20: 100% 785/785 [01:14<00:00, 10.48it/s, loss=6.17]\n",
            "Valid Epoch 11/20: 100% 378/378 [00:01<00:00, 214.42it/s, valid/loss=6.73, valid/accuracy=0.0036, valid/input_seq_len/accuracy-64=0.00281, valid/input_seq_len/accuracy-128=0.00581, valid/input_seq_len/accuracy-256=0.00428, valid/input_seq_len/accuracy-512=0.00309]\n",
            "Train Epoch 12/20: 100% 785/785 [01:15<00:00, 10.44it/s, loss=0.783]\n",
            "Valid Epoch 12/20: 100% 378/378 [00:01<00:00, 213.88it/s, valid/loss=0.575, valid/accuracy=0.866, valid/input_seq_len/accuracy-64=0.993, valid/input_seq_len/accuracy-128=0.963, valid/input_seq_len/accuracy-256=0.806, valid/input_seq_len/accuracy-512=0.45]\n",
            "Train Epoch 13/20: 100% 785/785 [01:15<00:00, 10.45it/s, loss=0.365]\n",
            "Valid Epoch 13/20: 100% 378/378 [00:01<00:00, 213.35it/s, valid/loss=0.388, valid/accuracy=0.907, valid/input_seq_len/accuracy-64=0.996, valid/input_seq_len/accuracy-128=0.986, valid/input_seq_len/accuracy-256=0.893, valid/input_seq_len/accuracy-512=0.574]\n",
            "Train Epoch 14/20: 100% 785/785 [01:15<00:00, 10.44it/s, loss=0.267]\n",
            "Valid Epoch 14/20: 100% 378/378 [00:01<00:00, 214.97it/s, valid/loss=0.341, valid/accuracy=0.918, valid/input_seq_len/accuracy-64=0.997, valid/input_seq_len/accuracy-128=0.991, valid/input_seq_len/accuracy-256=0.915, valid/input_seq_len/accuracy-512=0.609]\n",
            "Train Epoch 15/20: 100% 785/785 [01:15<00:00, 10.45it/s, loss=0.17]\n",
            "Valid Epoch 15/20: 100% 378/378 [00:01<00:00, 192.12it/s, valid/loss=0.297, valid/accuracy=0.927, valid/input_seq_len/accuracy-64=0.996, valid/input_seq_len/accuracy-128=0.994, valid/input_seq_len/accuracy-256=0.933, valid/input_seq_len/accuracy-512=0.648]\n",
            "Train Epoch 16/20: 100% 785/785 [01:15<00:00, 10.45it/s, loss=0.0962]\n",
            "Valid Epoch 16/20: 100% 378/378 [00:02<00:00, 186.31it/s, valid/loss=0.256, valid/accuracy=0.937, valid/input_seq_len/accuracy-64=0.997, valid/input_seq_len/accuracy-128=0.997, valid/input_seq_len/accuracy-256=0.949, valid/input_seq_len/accuracy-512=0.684]\n",
            "Train Epoch 17/20: 100% 785/785 [01:15<00:00, 10.46it/s, loss=0.0468]\n",
            "Valid Epoch 17/20: 100% 378/378 [00:01<00:00, 199.84it/s, valid/loss=0.216, valid/accuracy=0.945, valid/input_seq_len/accuracy-64=0.998, valid/input_seq_len/accuracy-128=0.998, valid/input_seq_len/accuracy-256=0.961, valid/input_seq_len/accuracy-512=0.718]\n",
            "Train Epoch 18/20: 100% 785/785 [01:15<00:00, 10.45it/s, loss=0.023]\n",
            "Valid Epoch 18/20: 100% 378/378 [00:01<00:00, 215.73it/s, valid/loss=0.192, valid/accuracy=0.95, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.998, valid/input_seq_len/accuracy-256=0.968, valid/input_seq_len/accuracy-512=0.74]\n",
            "Train Epoch 19/20: 100% 785/785 [01:15<00:00, 10.46it/s, loss=0.0167]\n",
            "Valid Epoch 19/20: 100% 378/378 [00:01<00:00, 214.03it/s, valid/loss=0.183, valid/accuracy=0.952, valid/input_seq_len/accuracy-64=0.999, valid/input_seq_len/accuracy-128=0.998, valid/input_seq_len/accuracy-256=0.97, valid/input_seq_len/accuracy-512=0.747]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss ███████████████████████████████▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss █████████████████████████▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 ▁▁▁▁▁▁▁▁▁▁▁▁████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 ▁▁▁▁▁▁▁▁▁▁▁▁▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 ▁▁▁▁▁▁▁▁▁▁▁▁▅▆▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 ▁▁▁▁▁▁▁▁▁▁▁▁████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss ▇▇▇▇▇▇▇▇▇▇▇█▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   num_parameters 1138688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       state_size 65536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/auxiliary_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       train/loss 0.01672\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  train/main_loss 0.01672\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   valid/accuracy 0.95212\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-128 0.99847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-256 0.9697\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid/input_seq_len/accuracy-512 0.74733\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  valid/input_seq_len/accuracy-64 0.99908\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       valid/loss 0.18337\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmamba-lr3.2e-02\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba/runs/f98njkv4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/llms_argh/HW_mamba\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241117_071137-f98njkv4/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m zoology.launch zoology/experiments/arxiv24_based_figure2/HW_config.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to solve AssertionError: libcuda.so cannot found!\n",
        "!echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFw-5H_pXjyY",
        "outputId": "198b7eab-1888-4b01-88dc-e4bee6e67e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd HW_mamba\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjdZw41nRpOc",
        "outputId": "e9035e97-0739-4163-9aa4-1890506f2cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HW_mamba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR0qwSKlfE2D",
        "outputId": "af177a6d-58cf-43da-d5ff-9cad26cc54e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running sweep default2024-11-17-03-55-40 with 16 configs\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoradi-arghavan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m failed to upsert bucket: returned error 403 Forbidden: {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertBucket\":null}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/HW_mamba/zoology/launch.py\", line 86, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/content/HW_mamba/zoology/launch.py\", line 61, in main\n",
            "    train(config)\n",
            "  File \"/content/HW_mamba/zoology/train.py\", line 193, in train\n",
            "    logger = WandbLogger(config)\n",
            "  File \"/content/HW_mamba/zoology/logger.py\", line 16, in __init__\n",
            "    self.run = wandb.init(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1270, in init\n",
            "    wandb._sentry.reraise(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/analytics/sentry.py\", line 161, in reraise\n",
            "    raise exc.with_traceback(sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1256, in init\n",
            "    return wi.init()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 847, in init\n",
            "    raise error\n",
            "wandb.errors.errors.CommError: failed to upsert bucket: returned error 403 Forbidden: {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertBucket\":null}}\n"
          ]
        }
      ],
      "source": [
        "!python -m zoology.launch zoology/experiments/arxiv24_based_figure2/configs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP8jIrH5ELSA",
        "outputId": "b15bf5a6-b8e1-426d-f761-c29f8ec7bbac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/zoology/zoology/launch.py\", line 86, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/content/zoology/zoology/launch.py\", line 44, in main\n",
            "    configs = config_module.configs\n",
            "AttributeError: module 'config_module' has no attribute 'configs'\n"
          ]
        }
      ],
      "source": [
        "!python -m zoology.launch zoology/analysis/paper/HW_figure2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Tev2XSVWOVUt",
        "outputId": "7e70c000-aeb4-4b49-f963-298fdd2a8d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.train_configs.2.input_seq_len\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 524.75x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from zoology.analysis.utils import fetch_wandb_runs\n",
        "import pdb\n",
        "\n",
        "\n",
        "def plot(\n",
        "    df: pd.DataFrame,\n",
        "    max_seq_len: int = 512,\n",
        "):\n",
        "    seq_len_key = \"data.train_configs.2.input_seq_len\"\n",
        "   # kv_pairs = \"data.train_configs.0.num_kv_pairs\"\n",
        "    print(seq_len_key)\n",
        "\n",
        "    plot_df = df.groupby([\n",
        "        \"model.name\",\n",
        "        \"model.d_model\",\n",
        "        seq_len_key\n",
        "    ])[\"accuracy/valid_4\"].max().reset_index()\n",
        "    #breakpoint()\n",
        "    #pdb.set_trace()\n",
        "   # run_dir = \"/var/cr05_data/sim_data/code/petting-zoo/\"\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    g = sns.relplot(\n",
        "        data=plot_df[plot_df[seq_len_key] <= max_seq_len],\n",
        "        y=\"valid/accuracy\",\n",
        "        col=seq_len_key,\n",
        "        x=\"model.d_model\",\n",
        "        hue=\"model.name\",\n",
        "        kind=\"line\",\n",
        "        marker=\"o\",\n",
        "        height=4,\n",
        "        aspect=1,\n",
        "    )\n",
        "\n",
        "    g.set( ylabel=\"Accuracy\", xlabel=\"Model dimension\")\n",
        "\n",
        "    # Set custom x-ticks\n",
        "    ticks = [64, 128, 256] # Modify this list as needed\n",
        "    for ax in g.axes.flat:\n",
        "        ax.set_xticks(ticks)\n",
        "\n",
        "        ax.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # This will keep the tick labels as integers rather than in scientific notation\n",
        "\n",
        "    # Set custom y-ticks\n",
        "    y_ticks = [0, 0.25, 0.5, 0.75, 1.0]\n",
        "    for ax in g.axes.flat:\n",
        "        ax.set_yticks(y_ticks)\n",
        "\n",
        "    for ax, title in zip(g.axes.flat, g.col_names):\n",
        "        ax.set_title(f\"Sequence Length: {title}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    df = fetch_wandb_runs(\n",
        "        launch_id=[\n",
        "            # \"default-2023-10-25-22-20-38\",\n",
        "            # \"default-2023-10-26-19-09-31\",\n",
        "            # \"default-2023-10-27-04-13-56\",\n",
        "            # \"default-2023-10-29-17-31-26\",\n",
        "            # \"default-2023-11-12-00-31-44\",\n",
        "            # \"default-2023-11-13-00-31-15\",\n",
        "            # \"default-2023-11-13-00-42-27\"\n",
        "\n",
        "            # \"default-2024-02-08-20-16-21\"\n",
        "            # \"default-2024-02-08-23-04-42\"\n",
        "            \"default-2024-11-16-05-24-11\",\n",
        "            \"default-2024-11-16-20-50-22\"\n",
        "        ],\n",
        "        project_name=\"HW_mamba\"\n",
        "    )\n",
        "    #pdb.set_trace()\n",
        "    # df[\"data.input_seq_len\"] = df[\"data.input_seq_len\"].fillna(df[\"data.0.input_seq_len\"])\n",
        "    plot(df=df)\n",
        "    plt.savefig(\"/content/HW_mamba/results.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kQr6bMLGKHm",
        "outputId": "4c7c298c-0dbc-4221-ccb7-9be22e26b196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_kv_pairs: num_kv_pairs, number: 4\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Input string\n",
        "input_string = \"valid/num_kv_pairs/accuracy-4\"\n",
        "\n",
        "# Extract using regular expressions\n",
        "match = re.search(r\"valid/([^/]+)/accuracy-(\\d+)\", input_string)\n",
        "if match:\n",
        "    num_kv_pairs = match.group(1)  # Captures \"num_kv_pairs\"\n",
        "    number = match.group(2)  # Captures \"4\"\n",
        "    print(f\"num_kv_pairs: {num_kv_pairs}, number: {number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJJB0XOXZwwj",
        "outputId": "92716829-5feb-4b19-c704-bdb80cc093bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36, 914)\n",
            "    model.d_model  valid/num_kv_pairs/accuracy-128  \\\n",
            "0              64                         0.004453   \n",
            "1              64                         0.007766   \n",
            "2              64                         0.002031   \n",
            "3              64                         0.103977   \n",
            "4              64                         0.004219   \n",
            "5              64                         0.006523   \n",
            "6              64                         0.002617   \n",
            "7              64                         0.349297   \n",
            "8              64                         0.006586   \n",
            "9              64                         0.004664   \n",
            "10             64                         0.005219   \n",
            "11             64                         0.272164   \n",
            "12            128                         0.068070   \n",
            "13            128                         0.009445   \n",
            "14            128                         0.007406   \n",
            "15            128                         0.383234   \n",
            "16            128                         0.006367   \n",
            "17            128                         0.006430   \n",
            "18            128                         0.450313   \n",
            "19            128                         0.009266   \n",
            "20            128                         0.006750   \n",
            "21            128                         0.009156   \n",
            "22            128                         0.796484   \n",
            "23            128                         0.766984   \n",
            "24            256                         0.011727   \n",
            "25            256                         0.029211   \n",
            "26            256                         0.001898   \n",
            "27            256                         0.001844   \n",
            "28            256                         0.061602   \n",
            "29            256                         0.226078   \n",
            "30            256                         0.012203   \n",
            "31            256                         0.000000   \n",
            "32            256                         0.016320   \n",
            "33            256                         0.009711   \n",
            "34            256                         0.006719   \n",
            "35            256                         0.000000   \n",
            "\n",
            "    data.train_configs.0.input_seq_len  data.batch_size.1  \n",
            "0                                   64                 16  \n",
            "1                                   64                 16  \n",
            "2                                   64                 16  \n",
            "3                                   64                 16  \n",
            "4                                   64                 16  \n",
            "5                                   64                 16  \n",
            "6                                   64                 16  \n",
            "7                                   64                 16  \n",
            "8                                   64                 16  \n",
            "9                                   64                 16  \n",
            "10                                  64                 16  \n",
            "11                                  64                 16  \n",
            "12                                  64                 16  \n",
            "13                                  64                 16  \n",
            "14                                  64                 16  \n",
            "15                                  64                 16  \n",
            "16                                  64                 16  \n",
            "17                                  64                 16  \n",
            "18                                  64                 16  \n",
            "19                                  64                 16  \n",
            "20                                  64                 16  \n",
            "21                                  64                 16  \n",
            "22                                  64                 16  \n",
            "23                                  64                 16  \n",
            "24                                  64                 16  \n",
            "25                                  64                 16  \n",
            "26                                  64                 16  \n",
            "27                                  64                 16  \n",
            "28                                  64                 16  \n",
            "29                                  64                 16  \n",
            "30                                  64                 16  \n",
            "31                                  64                 16  \n",
            "32                                  64                 16  \n",
            "33                                  64                 16  \n",
            "34                                  64                 16  \n",
            "35                                  64                 16  \n",
            "Index(['run_id', 'name', 'project', 'user', 'state', 'data.seed',\n",
            "       'data.cache_dir', 'data.batch_size.0', 'data.batch_size.1',\n",
            "       'data.force_cache',\n",
            "       ...\n",
            "       'gradients/graph_35backbone.layers.1.mixer.conv1d.bias',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.conv1d.weight',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.dt_proj.bias',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.dt_proj.weight',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.in_proj.weight',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.out_proj.weight',\n",
            "       'gradients/graph_35backbone.layers.1.mixer.x_proj.weight',\n",
            "       'gradients/graph_35backbone.layers.1.norm.weight',\n",
            "       'gradients/graph_35backbone.ln_f.bias',\n",
            "       'gradients/graph_35backbone.ln_f.weight'],\n",
            "      dtype='object', length=914)\n",
            "['valid/accuracy']\n"
          ]
        }
      ],
      "source": [
        "from zoology.analysis.utils import fetch_wandb_runs\n",
        "df = fetch_wandb_runs(\n",
        "        launch_id=[\n",
        "            # \"default-2023-10-25-22-20-38\",\n",
        "            # \"default-2023-10-26-19-09-31\",\n",
        "            # \"default-2023-10-27-04-13-56\",\n",
        "            # \"default-2023-10-29-17-31-26\",\n",
        "            # \"default-2023-11-12-00-31-44\",\n",
        "            # \"default-2023-11-13-00-31-15\",\n",
        "            # \"default-2023-11-13-00-42-27\"\n",
        "\n",
        "            # \"default-2024-02-08-20-16-21\"\n",
        "            # \"default-2024-02-08-23-04-42\"\n",
        "           # \"default-2024-11-16-05-24-11\"\n",
        "            \"default-2024-11-16-05-24-11\"\n",
        "        ],\n",
        "        project_name=\"HW_mamba\"\n",
        "    )\n",
        "print(df.shape)\n",
        "print(df[['model.d_model','valid/num_kv_pairs/accuracy-128','data.train_configs.0.input_seq_len','data.batch_size.1']])\n",
        "column_names=df.columns\n",
        "print(column_names)\n",
        "columns_with_data = [col for col in column_names if \"valid/accuracy\" in col.lower()]\n",
        "print(columns_with_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiG5ntnmbX-B",
        "outputId": "9406467b-a384-4893-be16-85b2f9e5d6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOVb38LKg3oJ"
      },
      "outputs": [],
      "source": [
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, ModuleConfig, FunctionConfig\n",
        "from zoology.data.associative_recall import MQARConfig\n",
        "\n",
        "config = TrainConfig(\n",
        "    max_epochs=20,\n",
        "    data=DataConfig(\n",
        "        train_configs=[MQARConfig(num_examples=10_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "        test_configs=[MQARConfig(num_examples=1_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "    ),\n",
        "    model=ModelConfig(\n",
        "        vocab_size=128,\n",
        "        sequence_mixer=ModuleConfig(name = \"zoology.mixers.attention.MHA\")\n",
        "    ),\n",
        ")\n",
        "configs = [config]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5bWkH67ilYm"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtB5LBMwifGs",
        "outputId": "0626fb04-b4f9-4243-af71-d8309e8912d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.return_types.sort(\n",
              "values=tensor([4, 3, 2]),\n",
              "indices=tensor([1, 2, 0]))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, ModuleConfig, FunctionConfig\n",
        "\n",
        "fn_config = FunctionConfig(name=\"torch.sort\", kwargs={\"descending\": True})\n",
        "fn = fn_config.instantiate()\n",
        "fn(torch.tensor([2,4,3])) # [4, 3, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deNLeNJbiuiW",
        "outputId": "7cd7f6c7-c8ff-4c25-e955-45c668e28bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "functools.partial(<function multiquery_ar at 0x7f2b4cdf3760>, num_kv_pairs=4)\n"
          ]
        }
      ],
      "source": [
        "fn_config= FunctionConfig(\n",
        "            name=\"zoology.data.associative_recall.multiquery_ar\",\n",
        "            kwargs={\"num_kv_pairs\": 4}\n",
        "        )\n",
        "fn = fn_config.instantiate()\n",
        "print(fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu-oGTWyov4r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from zoology.config import TrainConfig, ModelConfig, DataConfig, FunctionConfig, ModuleConfig\n",
        "from zoology.data.associative_recall import MQARConfig\n",
        "\n",
        "configs = []\n",
        "\n",
        "for lr in np.logspace(-4, -2, 10):\n",
        "\n",
        "  config = TrainConfig(\n",
        "      max_epochs=20,\n",
        "      data=DataConfig(\n",
        "      train_configs=[MQARConfig(num_examples=20_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "      test_configs=[MQARConfig(num_examples=1_000, vocab_size=128, input_seq_len=64, kwargs={\"num_kv_pairs\": 4})],\n",
        "      ),\n",
        "      model=ModelConfig(\n",
        "         vocab_size=256,\n",
        "         max_position_embeddings=64,\n",
        "         sequence_mixer=ModuleConfig(\n",
        "               name=\"zoology.mixers.attention.MHA\",\n",
        "               kwargs={\"dropout\": 0.1, \"num_heads\": 1})\n",
        "         ),\n",
        "      learning_rate=lr\n",
        "      )\n",
        "  configs.append(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMnmmsqAsI2xHJr/ag9VOuN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}